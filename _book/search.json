[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Connectivity for Disaster Resiliance",
    "section": "",
    "text": "Preface\ns"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "2 MAP\nAÑadir An innovative approach to assess the impact of urban flooding: Modeling transportation system failure due to urban flooding\nThis is a book created from markdown and executable code.\nSee (knuth84?) for additional discussion of literate programming.\nShow the code\n1 + 1\n\n\n[1] 2\nThe research objective is to improve urban resilience by identifying critical infrastructures necessary for accessing healthcare facilities, comparing road connectivity and accessibility. The following research questions are addressed in this study:"
  },
  {
    "objectID": "intro.html#research-questions",
    "href": "intro.html#research-questions",
    "title": "1  Introduction",
    "section": "2.1 Research questions",
    "text": "2.1 Research questions\n\nHow did the road connectivity of the city network change after being impacted by the floodings in Rio Grande do Sul based on Edge Betweenness Centrality?\nWhich healthcare facilities were most affected by the floodings based on accessibility metrics?\nIn which area of a city’s network should decisions be made to reinforce or redesign routes to optimize healthcare accessibility and ensure minimal disruption during flood events?"
  },
  {
    "objectID": "methodology.html#data",
    "href": "methodology.html#data",
    "title": "2  Methodology",
    "section": "2.1 Data",
    "text": "2.1 Data"
  },
  {
    "objectID": "methodology.html#framework",
    "href": "methodology.html#framework",
    "title": "2  Methodology",
    "section": "2.2 Framework",
    "text": "2.2 Framework"
  },
  {
    "objectID": "methodology.html#area-of-interest",
    "href": "methodology.html#area-of-interest",
    "title": "2  Methodology",
    "section": "2.3 Area of Interest",
    "text": "2.3 Area of Interest\n\n2.3.1 Import\nThe tool ogr2ogr imported the data and adjust the geometry according to the recommendations. The recommendation was “pgRouting processes single features more effficiently than multiegeometries, so whenver possible, choose single over multi” mentioned in the book pgrouting.\n\n\nShow the code\n## OSM geometry: porto_alegre_net_pre.geojson\nogr2ogr -f PostgreSQL PG:\"host=localhost port= 25432 user=docker password=docker dbname=gis schemas=heigit\" /home/ricardo/HeiGIT-Github/data_required_porto_alegre/porto_alegre_net_pre.geojson -nln porto_alegre_net_pre -lco GEOMETRY_NAME=the_geom -nlt LINESTRING -explodecollections \n\n## Administrative units: nuts.geojson\nogr2ogr -f PostgreSQL PG:\"host=localhost port= 25432 user=docker password=docker dbname=gis schemas=heigit\" /home/ricardo/HeiGIT-Github/data_required_porto_alegre/nuts.geojson -nln nuts -lco GEOMETRY_NAME=geom\n\n## Flooding extent: flooding_rio_grande_do_sul.geojson\nogr2ogr -f PostgreSQL PG:\"host=localhost port= 25432 user=docker password=docker dbname=gis schemas=heigit\" /home/ricardo/HeiGIT-Github/data_required_porto_alegre/flooding_rio_grande_do_sul.geojson -nln flooding_rio_grande_do_sul -lco GEOMETRY_NAME=the_geom \n\n## Building density: urban_center_4326.geojson\nogr2ogr -f PostgreSQL PG:\"host=localhost port= 25432 user=docker password=docker dbname=gis schemas=heigit\" /home/ricardo/HeiGIT-Github/data_required_porto_alegre/urban_center_4326.geojson -nln urban_center_4326 -lco GEOMETRY_NAME=geom \n\n## Hospitals\n### From Rio Grande do Sul Geoportal\nogr2ogr -f PostgreSQL PG:\"host=localhost port= 25432 user=docker password=docker dbname=gis schemas=heigit\" /home/ricardo/HeiGIT-Github/data_required_porto_alegre/Hospitais_com_Leitos_de_UTIs_no_RS.geojson -nln hospitals_bed_rs -lco GEOMETRY_NAME=geom\n\n\n\n2.3.1.1 Network: OpenStreetMap (OSM)\nThe following SQL code created the command to import OpenStreetMap (OSM) network using osmium. Firstly using the GHS-SMOD dataset the Global Human Settlement in Porto Alegre is chosen. Secondly, this GHS selected is used to create the bounding box that it is lastly used to generate the osmium code. The OSM network obtained with this osmium command was the input required for OpenRouteService (ORS).\n\n\nShow the code\n--- GHS urban area that intersected with Porto Alegre city\nWITH porto_alegre_ghs AS(\n    SELECT \n       ghs.*\n    FROM\n       urban_center_4326 AS ghs\n    JOIN\n       nuts \n    ON \n       st_intersects(nuts.geom, ghs.geom)\n    WHERE \n        nuts.shapename = 'Porto Alegre'),\n--- Bounding Box that contained the GHS in Porto Alegre\nporto_alegre_ghs_bbox AS(\n    SELECT \n        st_setsrid(st_extent(geom),4326) as geom_bbox\n    FROM \n        porto_alegre_ghs),\n--- The command used the Porto Alegre GHS and its Bounding Box to import the OpenStreet Network. \nporto_alegre_ghs_bbox_osmium_command AS (\n    SELECT \n        ST_XMin(ST_SnapToGrid(geom_bbox, 0.0001)) AS min_lon,\n        St_xmax(ST_SnapToGrid(geom_bbox,0.0001)) AS max_lon,\n        St_ymin(ST_SnapToGrid(geom_bbox,0.0001)) AS min_lat,\n        St_ymax(ST_SnapToGrid(geom_bbox, 0.0001)) AS max_lat\n    FROM porto_alegre_ghs_bbox)\nSELECT\n    'osmium extract -b ' \n    || min_lon || ',' || min_lat || ',' || max_lon || ',' || max_lat || \n    ' sul-240501.osm.pbf -o puerto_alegre_urban_center.osm.pbf' AS osmium_command\nFROM porto_alegre_ghs_bbox_osmium_command;\n\n\n\n\n2.3.1.2 Graph: OpenRouteService (OSM)\nA docker for OpenRouteService transformed the OSM network that covered the GHS in Porto Alegre into a graph. In the “ors-config.yml” from OpenRotueService (ORS), the “source_file” parameter is set with the following directory.\n\n\nShow the code\nsource_file: /home/ors/files/puerto_alegre_urban_center.osm.pbf\n\n\nOpenRouteService (ORS) created a a routable network, assigining costs and adding information for each node, namely, “fromId” and “toId”. The network named as “porto_alegre_net” extracted from ORS was created using the R script “get_graph” from Marcel Reinmuth.\n\n\n\n2.3.2 Cleaning\nThe parameters start_vid, end_vid named “fromid” and “toid” in the network dataset from openrouteservice are transform into bigint data type to run the algorithm pgr_dijkstra as the official documentation indicates.\n\n\nShow the code\nselect * from porto_alegre_net_pre; \nALTER TABLE porto_alegre_net_pre \n    ALTER COLUMN \"toid\" type bigint,\n    ALTER COLUMN \"fromid\" type bigint,\n    ALTER COLUMN \"ogc_fid\" type bigint;\n\n\n\n2.3.2.1 Graph\nBefore using the graph, a quick inspection of the graph using the pgrouting function pgr_strongComponents() revealed how many components or isolated self-connecting network the graph had.\n\n\nShow the code\n--- Create a vertice table for pgr_dijkstra()\nSELECT \n  pgr_createVerticesTable('porto_alegre_net_pre', source:='fromid', target:='toid');\n  \n---- Add data to the vertices created table \nCREATE TABLE component_analysis_network_porto AS\nWITH porto_alegre_net_component AS (\nSELECT \n  * \nFROM \n  pgr_strongComponents('SELECT ogc_fid AS id,\n                               fromid AS source,\n                               toid AS target,\n                               weight AS cost \n                        FROM \n                              porto_alegre_net_pre')),\nporto_alegre_net_component_geom AS (\nSELECT \n    net.*,\n    net_geom.the_geom\nFROM \n    porto_alegre_net_component AS net\nJOIN \n    porto_alegre_net_pre  AS net_geom\nON \n    net.node = net_geom.fromid)\nSELECT \n    component,\n    st_union(the_geom) AS the_geom,\n    st_length(st_union(the_geom)::geography)::int AS length\nFROM  \n    porto_alegre_net_component_geom\nGROUP BY component\nORDER BY length DESC;\n\n\nThe largest length selected the network component of the study. The following code created this table ruling out the rest of the relatively small networks.\n\n\nShow the code\nCREATE TABLE porto_alegre_net_largest AS\n---- Obtain again table classifying nodes in different components           \nWITH porto_alegre_net_component AS (\nSELECT \n  * \nFROM \n  pgr_strongComponents('SELECT\n                               ogc_fid AS id,\n                               fromid AS source,\n                               toid AS target,\n                               weight AS cost \n                        FROM \n                              porto_alegre_net_pre')),\n--- Calculate the largest component from the network\nlargest_component_net AS (\n    SELECT \n        component\n    FROM \n        component_analysis_network_porto \n    LIMIT 1),\n--- Using the largest component from the network to filter\nlargeset_component_network_porto AS (\nSELECT\n    *  \nFROM\n    porto_alegre_net_component,\n    largest_component_net\nWHERE \n    porto_alegre_net_component.component = largest_component_net.component)\nSELECT \n    net_multi_component.*\nFROM \n    porto_alegre_net_pre AS net_multi_component,\n    largeset_component_network_porto AS net_largest_component\nWHERE  \n    net_multi_component.fromid IN (net_largest_component.node);\n\n\n\n\n2.3.2.2 Flooding mask\nThe downloaded flooding extent covered a larger area in Rio Grande do Sul. However, our area of interest for urban dense city was only Porto Alegre. Therefore, a serie of operations reduced the area focusing on Porto Alegre and at the same time improved the performance reducing the size of the mask.\nSubdividing the flooding mask to make the spatial indexes more efficient was the first step. The reason was the higher number of vertices of large objects and larges bounding boxes that hinder the spatial index performance (Link). After the spatial indexes were enable, the intersection with the Porto Alegre region subset the data.\n\n\nShow the code\n--- Select the GHS area that intersects with Porto Alegre\nCREATE TABLE flooding_subdivided_porto AS\nWITH porto_alegre_ghs AS(\n    SELECT \n       ghs.*\n    FROM\n       urban_center_4326 AS ghs\n    JOIN\n       nuts \n    ON \n       st_intersects(nuts.geom, ghs.geom)\n    WHERE \n        nuts.shapename = 'Porto Alegre'),\n--- Bounding Box that contained the GHS in Porto Alegre\nporto_alegre_ghs_bbox AS(\n    SELECT \n        st_setsrid(st_extent(geom),4326) as geom_bbox\n    FROM \n        porto_alegre_ghs),\n---Subdivide the flood extent to increase spatial indexes performance \nflooding_sul_subdivided AS (\n        SELECT \n            st_subdivide(geom) as the_geom\n        FROM\n            flooding_rio_grande_do_sul) \n---- Select the flooding subunits that intersects with the previous bounding box\nSELECT \n    flooding_sul_subdivided.* \nFROM \n    flooding_sul_subdivided, \n    porto_alegre_ghs_bbox\nWHERE \n    st_intersects(flooding_sul_subdivided.the_geom, porto_alegre_ghs_bbox.geom_bbox);\n\n\nAdditionally, the following code dissolve the borders to break the multipolygon into simple polygons to improve the performance of functions such as st_difference() (link).\n\n\nShow the code\nCREATE TABLE flooding_cleaned_porto AS\n    SELECT (ST_Dump(the_geom)).geom::geometry(polygon, 4326) geom FROM flooding_subdivided_porto;\n    \nCREATE TABLE flooding_cleaned_porto_union AS\n    SELECT ST_Union(geom)::geometry(multipolygon, 4326) geom FROM flooding_cleaned_porto;\n    \nCREATE TABLE flooding_cleaned_porto_union_simple AS\n    SELECT (ST_Dump(geom)).geom::geometry(polygon, 4326) geom FROM flooding_cleaned_porto_union;\n    \nSELECT COUNT(*)\n     FROM flooding_cleaned_porto_union_simple ; --- count= 54.\n\nDELETE FROM flooding_cleaned_porto_union_simple WHERE ST_Area(geom) &lt; 0.0001; ---count= 2.\n\n\nThis allowed to calculate the area of each polygon finding slivers that were removed using the following code.\n\n\n\n2.3.3 Transform\nThe creation of the network after the disaster using the modified flooding mask and the creation of the origin-destination are considered in this section. The following code set the paremeters before carrying out these transformations following post 1 and post2.\nFirstly, add spatial index everywhere:\n\n\nShow the code\nCREATE INDEX idx_porto_alegre_net_largest_geom ON porto_alegre_net_largest USING gist(the_geom);\nCREATE INDEX idx_porto_alegre_net_largest_source ON porto_alegre_net_largest USING btree(fromid);\nCREATE INDEX idx_porto_alegre_net_largest_target ON porto_alegre_net_largest USING btree(toid);\nCREATE INDEX idx_porto_alegre_net_largest_id ON porto_alegre_net_largest USING btree(ogc_fid);\nCREATE INDEX idx_porto_alegre_net_largest_cost ON porto_alegre_net_largest USING btree(weight);\n\n\n\n\nShow the code\nSET max_parallel_workers_per_gather =4;\n\n\n\n\nShow the code\nCLUSTER porto_alegre_net_largest USING porto_alegre_net_largest;\n\n\n\n2.3.3.1 Network after the disaster\nA naive approach overlaying the flooding mask with the road network by the function st_difference() caused the crashing of the session. The follwing multi-step methodology reduced the processing cost make the query feasible using less resources.\n\nNetwork inside the flooding mask\nNetwork outside the flooding mask\nNetwork on the boundaries\nApplying st_difference\nUniting network external to the boundaries and network from outside\n\n1.The network contained by the flooding extent and its intersection is selected.\n\n\nShow the code\n------------- network inside\nCREATE TABLE porto_alegre_street_in_v2 AS\nSELECT net.id,\n    CASE \n        WHEN ST_Contains(flood.the_geom, net.the_geom)\n        THEN net.the_geom\n        ELSE st_intersection(net.the_geom, flood.the_geom)\n    END AS  geom\nFROM porto_alegre_net_largest net\nJOIN flooding_subdivided_porto flood\nON st_intersects(net.the_geom, flood.the_geom);\n\n\n\nInstead of using columns containing geometrical variables, the numerical ID is used. For this the previous step, which created a table with the network inside the flooding mask was required.\n\n\n\nShow the code\n----------------- network outside\n----------------- network outside\nCREATE TABLE porto_alegre_street_out_v2 AS\nSELECT net.*\nFROM porto_alegre_net_largest net\nWHERE net.id NOT IN (\n    SELECT net.id\n    FROM porto_alegre_street_in_v2 net);\n\n\n\nThe function St_ExteriorRing() casted the geometry into linestring reducing the processing costs. This exterior ring selected the road segments located on the boundaries.\n\n\n\nShow the code\nCREATE TABLE porto_alegre_net_outside_v2 AS\nWITH porto_alegre_ghs AS(\n    SELECT \n       ghs.*\n    FROM\n       urban_center_4326 AS ghs\n    JOIN\n       nuts \n    ON \n       st_intersects(nuts.geom, ghs.geom)\n    WHERE \n        nuts.shapename = 'Porto Alegre'),\n--- Bounding Box that contained the GHS in Porto Alegre\nporto_alegre_ghs_bbox AS(\n    SELECT \n        st_setsrid(st_extent(geom),4326) as geom_bbox\n    FROM \n        porto_alegre_ghs),\nflooding_sul_subdivided AS (\n        SELECT \n            st_subdivide(geom) as the_geom\n        FROM\n            flooding_rio_grande_do_sul),\nexterior_ring_porto_alegre_v2 AS (\nSELECT \n    ST_ExteriorRing((ST_Dump(union_geom)).geom) as geom\nFROM (\n    SELECT \n        ST_Union(flood.the_geom) as union_geom\n    FROM \n        porto_alegre_ghs_bbox as bbox\n    JOIN \n        flooding_sul_subdivided as flood\n    ON \n        ST_Intersects(flood.the_geom, bbox.geom_bbox)\n) AS subquery)\nSELECT net.id,\n    CASE\n        WHEN NOT ST_Contains(flood.geom, net.the_geom)\n        THEN net.the_geom\n            ELSE st_intersection(net.the_geom, flood.geom)\n    END AS  geom,\n    net.target,\n       net.source,\n       cost,\n       \"unidirectid\",\n       \"bidirectid\"\nFROM\nporto_alegre_net_largest AS net\nJOIN exterior_ring_porto_alegre_v2 flood ON\nst_intersects(net.the_geom, flood.geom);\n\n\n\n\n\n\n\nShow the code\n---- For the network\nCREATE INDEX idx_porto_alegre_net_outside_v2 ON porto_alegre_net_outside_v2 USING gist (geom);\n\nCLUSTER porto_alegre_net_outside_v2 USING idx_porto_alegre_net_outside_v2;\n\n--- For the flooding mask\nCREATE INDEX flooding_sul_subdivided_idx ON flooding_sul_subdivided USING gist (the_geom);\n\nCLUSTER flooding_sul_subdivided USING flooding_sul_subdivided_idx;\n\n---- Before doing difference\nVACUUM(FULL, ANALYZE) porto_alegre_net_outside_v2;\nVACUUM(FULL, ANALYZE) flooding_sul_subdivided;\n\n\nLastly, the difference is created using:\n\n\nShow the code\nCREATE TABLE flooding_symple as \nSELECT st_union(geom) as the_geom FROM flooding_cleaned_porto_union_simple;\n\nCREATE INDEX flooding_symple_idx ON flooding_symple USING gist (the_geom);\nCLUSTER flooding_symple USING flooding_symple_idx;\n\nCREATE TABLE difference_outside_flood_v3 AS\nSELECT net.id,\n        target,\n        source,\n        cost,\n        unidirectid,\n        bidirectid,\nst_difference(net.geom, flood.the_geom) AS the_geom\nFROM porto_alegre_net_outside_v2 AS net,\nflooding_symple  AS flood;\n\n\n\n\nShow the code\nporto_alegre_net_pre &lt;- sf::st_read(eisenberg_connection, \"porto_alegre_net_largest\")\ncentrality_pre &lt;- sf::st_read(eisenberg_connection, \"centrality_weighted_100_bidirect_cleaned\")\nflooding &lt;- sf::st_read(eisenberg_connection, \"flooding_cleaned_porto\")\nnet_in &lt;- sf::st_read(eisenberg_connection, \"porto_alegre_street_in_v2\")\n## subset\nsubset_network_pre &lt;-  sf::st_read(eisenberg_connection, \"porto_alegre_net_largest_subset\")\nsubset_network_in &lt;- sf::st_read(\"/home/ricardo/heigit_bookdown/data/porto_alegre_street_in_v3_subset.geojson\")\nsubset_network_out &lt;- sf::st_read(eisenberg_connection, \"porto_alegre_street_out_v3\") |&gt; st_as_sfc() \nsubset_network_outside_flood &lt;-sf::st_read(eisenberg_connection, \"difference_outside_flood_v4\")\nsubset_network_post &lt;- sf::st_read(eisenberg_connection, \"porto_alegre_street_united_v3\")\nflooding &lt;- sf::st_read(eisenberg_connection, \"flooding_symple\") \nflooding &lt;- st_union(flooding$the_geom, by_feature= FALSE)\n\n## centrality\nmapview(subset_network_pre,\n          color=\"#d4e7e7\",\n          lwd= 0.5,\n          layer.name=\"Pre-flooding network\",\n          popup=popupTable(subset_network_pre,\n          zcol=c(\"id\",\"source\",\"target\",\"bidirectid\"))) +\n  mapview(flooding,\n          color=\"darkblue\",\n          alpha.regions= 0.5,\n          layer.name=\"Flooding layer\") + \n  mapview(subset_network_in,\n          color=\"red\",\n          lwd= 0.5,\n          legend = FALSE,\n          hide = TRUE,\n          layer.name=\"Network in the flooding\") +\n  mapview(subset_network_out,\n          color=\"darkcyan\",\n          lwd= 0.5,\n          hide = TRUE,\n          layer.name=\"Flooding outside the network\",\n          popup=popupTable(subset_network_out)) +\n  mapview(subset_network_outside_flood,\n          color=\"yellow\",\n          lwd= 0.8,\n          legend = FALSE,\n          layer.name=\"Boundary network\",\n          popup=popupTable(subset_network_outside_flood)) +\n    mapview(subset_network_post,\n          color=\"darkorange\",\n          lwd= 0.8,\n          hide =TRUE,\n          layer.name=\"Post-flooding network\",\n          popup=popupTable(subset_network_post))\n\n\nAs a final step, they are merged.\n\n\nShow the code\n-----------\nCREATE TABLE porto_alegre_street_united AS\nSELECT *\nFROM porto_alegre_street_out\nUNION\nSELECT *\nFROM difference_outside_flood_v2;"
  },
  {
    "objectID": "methodology.html#routable-network",
    "href": "methodology.html#routable-network",
    "title": "2  Methodology",
    "section": "2.4 Routable network",
    "text": "2.4 Routable network\n\n\nShow the code\nSELECT pgr_createVerticesTable(\n            'porto_alegre_net_largest',\n            the_geom:= 'the_geom',\n            source:= 'fromid',\n            target:= 'toid')\n\n\n\n\nShow the code\nALTER TABLE od_2728\nADD COLUMN id SERIAL PRIMARY KEY;\n\n\n\n2.4.1 Post-scenario\n\n\nShow the code\n---- Create vertices\nSELECT pgr_createverticesTable('porto_alegre_net_post_v5');\n----- Obtain components to be used later as a filter\nCREATE TABLE component_analysis_network_porto_post AS\nWITH porto_alegre_net_component_post AS (\nSELECT \n  * \nFROM \n  pgr_strongComponents('SELECT id,\n                               source,\n                               target,\n                               cost \n                        FROM \n                              porto_alegre_net_post_v5')),\nporto_alegre_net_component_geom_post AS (\nSELECT \n    net.*,\n    net_geom.the_geom\nFROM \n    porto_alegre_net_component_post AS net\nJOIN \n    porto_alegre_net_post_v5  AS net_geom\nON \n    net.node = net_geom.source)\nSELECT \n    component,\n    st_union(the_geom) AS the_geom,\n    st_length(st_union(the_geom)::geography)::int AS length\nFROM  \n    porto_alegre_net_component_geom_post\nGROUP BY component\nORDER BY length DESC;\n--- Summarise by component\nCREATE TABLE components_network_post AS\nWITH porto_alegre_net_component_post AS (\nSELECT \n  * \nFROM \n  pgr_strongComponents('SELECT\n                               id,\n                               source,\n                               target,\n                               cost \n                        FROM \n                              porto_alegre_net_post_v5')),\n--- Calculate the largest component from the network\nlargests_component_net_post AS (\n    SELECT \n        component,\n        the_geom,\n        length::int\n    FROM \n        component_analysis_network_porto_post)\nSELECT * FROM largests_component_net_post WHERE ;\n\n---- Visualize which are more important\nCREATE TABLE main_components_post AS\nSELECT \n    * \nFROM \n    components_network_post\nWHERE\n    component IN (21,14,5187);\n\n-------------- Remember to justify why 5\n\nCREATE TABLE prueba_largest_network_post AS\nWITH porto_alegre_net_component_post AS (\nSELECT \n  * \nFROM \n  pgr_strongComponents('SELECT\n                               id,\n                               source,\n                               target,\n                               cost \n                        FROM \n                              porto_alegre_net_post_v5')),\n--- Calculate the largest component from the network\nlargest_component_net_post AS (\n    SELECT \n        component\n    FROM \n        component_analysis_network_porto_post\n    LIMIT 5),\n--- Using the largest component from the network to filter\nlargeset_component_network_porto_post AS (\nSELECT\n    *  \nFROM\n    porto_alegre_net_component_post,\n    largest_component_net_post\nWHERE \n    porto_alegre_net_component_post.component = largest_component_net_post.component)\nSELECT \n    net_multi_component.*\nFROM \n    porto_alegre_net_post_v5 AS net_multi_component,\n    largeset_component_network_porto_post AS net_largest_component\nWHERE  \n    net_multi_component.source IN (net_largest_component.node);\n--- Create 100 origin samples from the snapped points post-scenario\n\nCREATE TABLE weight_sampling_100_origin_post  AS\nWITH porto_100_origin AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped_post \n        ORDER BY random() LIMIT 100)\n        SELECT * FROM  porto_100_origin;  \n--- Create 100 destination from the snapped points post-scenario\n\nCREATE TABLE weight_sampling_100_destination_post  AS\nWITH porto_100_destination AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped_post \n        ORDER BY random() LIMIT 100)\n        SELECT * FROM  porto_100_destination;  \n--- Indeces on origin\nCREATE INDEX weight_sampling_100_origin_idx_pt_id ON weight_sampling_100_origin USING btree(pt_id);\nCREATE INDEX weight_sampling_100_origin_idx_pt_id ON weight_sampling_100_origin USING btree(net_id);\nCREATE INDEX weight_sampling_100_origin_idx_the_geom ON weight_sampling_100_origin USING gist(the_geom);\n--- Indeces on destination\nCREATE INDEX weight_sampling_100_destination_post_idx_pt_id ON weight_sampling_100_destination_post USING btree(pt_id);\nCREATE INDEX weight_sampling_100_destination_post_idx_net_id ON weight_sampling_100_destination_post USING btree(net_id);\nCREATE INDEX weight_sampling_100_destination_post_idx_the_geom ON weight_sampling_100_destination_post USING gist(the_geom);\n---- Indexes on origin\nCREATE INDEX weight_sampling_100_origin_post_idx_pt_id ON weight_sampling_100_origin_post USING btree(pt_id);\nCREATE INDEX weight_sampling_100_origin_post_idx_net_id ON weight_sampling_100_origin_post USING btree(net_id);\nCREATE INDEX weight_sampling_100_origin_post_idx_the_geom ON weight_sampling_100_origin_post USING gist(the_geom);\n---- Index on the new network\nCREATE INDEX prueba_largest_network_post_idx_GEOM ON prueba_largest_network_post USING gist(the_geom);\nCREATE INDEX prueba_largest_network_post_idx_id ON prueba_largest_network_post USING btree(id);\nCREATE INDEX prueba_largest_network_post_idx_target ON prueba_largest_network_post USING btree(target);\nCREATE INDEX prueba_largest_network_post_idx_source ON prueba_largest_network_post USING btree(source);\nCREATE INDEX prueba_largest_network_post_idx_cost ON prueba_largest_network_post USING btree(cost);\n---- Cluster \nCLUSTER prueba_largest_network_post USING prueba_largest_network_post_idx_GEOM;\n---- Vacuum clean\nVACUUM(full, ANALYZE) weight_sampling_100_origin;\nVACUUM(full, ANALYZE) weight_sampling_100_destination;\nVACUUM(full, ANALYZE) porto_alegre_net_largest;"
  },
  {
    "objectID": "methodology.html#centrality-analysis",
    "href": "methodology.html#centrality-analysis",
    "title": "2  Methodology",
    "section": "2.5 Centrality Analysis",
    "text": "2.5 Centrality Analysis\n\n2.5.1 Origin-Destination\n\n2.5.1.1 Random distribution (naive)\nA series of regular points that represented the origin and destination on the Area of Interest is created with the function “I_Grid_Point_Series”.\n\n\nShow the code\n--- Creating sampel data:\nCREATE OR REPLACE FUNCTION I_Grid_Point_Series(geom geometry, x_side decimal, y_side decimal, spheroid boolean default false)\nRETURNS SETOF geometry AS $BODY$\nDECLARE\nx_max decimal;\ny_max decimal;\nx_min decimal;\ny_min decimal;\nsrid integer := 4326;\ninput_srid integer;\nx_series DECIMAL;\ny_series DECIMAL;\nBEGIN\nCASE st_srid(geom) WHEN 0 THEN\n  geom := ST_SetSRID(geom, srid);\n  RAISE NOTICE 'SRID Not Found.';\n    ELSE\n        RAISE NOTICE 'SRID Found.';\n    END CASE;\n\n    CASE spheroid WHEN false THEN\n        RAISE NOTICE 'Spheroid False';\n    else\n        srid := 900913;\n        RAISE NOTICE 'Spheroid True';\n    END CASE;\n    input_srid:=st_srid(geom);\n    geom := st_transform(geom, srid);\n    x_max := ST_XMax(geom);\n    y_max := ST_YMax(geom);\n    x_min := ST_XMin(geom);\n    y_min := ST_YMin(geom);\n    x_series := CEIL ( @( x_max - x_min ) / x_side);\n    y_series := CEIL ( @( y_max - y_min ) / y_side );\nRETURN QUERY\nSELECT st_collect(st_setsrid(ST_MakePoint(x * x_side + x_min, y*y_side + y_min), srid)) FROM\ngenerate_series(0, x_series) as x,\ngenerate_series(0, y_series) as y\nWHERE st_intersects(st_setsrid(ST_MakePoint(x*x_side + x_min, y*y_side + y_min), srid), geom);\nEND;\n$BODY$ LANGUAGE plpgsql IMMUTABLE STRICT;\n\n\nThe following code created 1258 points representing the origin or destination regularly separated by 0.01º.\n\n\nShow the code\nCREATE TABLE regular_point_od AS (\nWITH multipoint_regular AS(\nselect \n    I_Grid_Point_Series(geom, 0.01,0.01, false) AS geom\n    from porto_alegre_bbox as geom),\npoint_regular AS(\nSELECT \n    st_setsrid((st_dump(geom)).geom, 4326)::geometry(Point, 4326) AS geom\nFROM  multipoint_regular)\nSELECT \n    row_number() over() AS id,\n    geom\nFROM \n    point_regular);\n\n\nThe application of two indexes improved further queries on this new table. This was recommended because these points were outside the network requiring snapping, which is a spatial operation with relatively high computational costs.\n\n\nShow the code\nCREATE INDEX idx_regular_point_od_geom ON regular_point_od USING GIST (geom);\nCREATE INDEX idx_regular_point_od_id ON regular_point_od USING btree(id);\n\n\nApart from indexing the geometry column and the id, the query is constrained to a buffer of 0.02º to reduce computational costs.\n\n\n2.5.1.2 Weighted on building volume\n\n\nShow the code\n# Import data\n## raster\nbuildings &lt;- terra::rast('/home/ricardo/HeiGIT-Github/do_not_push_too_large/GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0/GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0.tif')\npop_ghs &lt;- 2728\n## AoI\naoi_bbox &lt;- sf::read_sf('/home/ricardo/HeiGIT-Github/data_required_porto_alegre/porto_alegre_bbox_derived.geojson')\n## reproject for clipping\naoi_bbox_reproj &lt;- aoi_bbox |&gt; st_transform(crs(buildings)) |&gt; as_Spatial()\nbuild_cropped &lt;- crop(buildings, aoi_bbox_reproj)\n## reproject for sampling\nbuild_4326 &lt;- terra::project(build_cropped, crs(aoi_bbox))\n## weighted sampling\nod &lt;- spatSample(build_cropped, pop_ghs, \"weights\", as.points=TRUE, ) |&gt; st_as_sf() |&gt; st_transform(4326)\nnames(od)[1] &lt;- 'building'\nDBI::dbWriteTable(connection, \n                  DBI::Id(schema = \"public\", table = \"od_2728\"), \n                  od)\n\n\nSnap the points\n\n\nShow the code\n--- Create ID column\n\nALTER TABLE od_2728\nADD COLUMN id serial primary key;\n\n--- Snap all the Apoints based on building density to the closest vertice within the network\nCREATE TABLE od_2728_snapped AS\nSELECT DISTINCT ON (net.id)\n       pt.id AS pt_id,\n       net.id AS net_id,\n       net.the_geom\nFROM \n(select * \nFROM \n    od_2728 as pt) as pt\nCROSS JOIN\nLATERAL (SELECT\n        * \n        FROM porto_alegre_net_largest_vertices_pgr AS net\n         ORDER BY net.the_geom &lt;-&gt; pt.geometry \n        LIMIT 1) AS net;\n--- Create 100 origin samples from the snapped points\n\nCREATE TABLE weight_sampling_100_origin  AS\nWITH porto_100_origin AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped \n        ORDER BY random() LIMIT 100)\n        SELECT * FROM  porto_100_origin;  \n--- Create 100 destination from the snapped points\n\nCREATE TABLE weight_sampling_100_destination  AS\nWITH porto_100_destination AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped \n        ORDER BY random() LIMIT 100)\n        SELECT * FROM  porto_100_destination;  \n--- Indeces on origin\nCREATE INDEX weight_sampling_100_origin_idx_pt_id ON weight_sampling_100_origin USING btree(pt_id);\nCREATE INDEX weight_sampling_100_origin_idx_pt_id ON weight_sampling_100_origin USING btree(net_id);\nCREATE INDEX weight_sampling_100_origin_idx_the_geom ON weight_sampling_100_origin USING gist(the_geom);\n--- Indeces on destination\nCREATE INDEX weight_sampling_1000_destination_idx_pt_id ON weight_sampling_1000_destination USING btree(pt_id);\nCREATE INDEX weight_sampling_1000_destination_idx_net_id ON weight_sampling_1000_destination USING btree(net_id);\nCREATE INDEX weight_sampling_1000_destination_idx_the_geom ON weight_sampling_1000_destination USING gist(the_geom);\n---- Cluster\nCLUSTER porto_alegre_net_largest USING idx_porto_alegre_net_largest_geom;\n---- Vacuum clean\nVACUUM(full, ANALYZE) weight_sampling_100_origin;\nVACUUM(full, ANALYZE) weight_sampling_100_destination;\nVACUUM(full, ANALYZE) porto_alegre_net_largest;\n\n\n\n\nShow the code\n---- add ID\nALTER TABLE od_77763\nADD COLUMN id serial;\n---- Rename the column name\nALTER TABLE od_77763\nrename \"GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0\" \nto \"build\";\n---- create spatial index\nCREATE INDEX idx_od_77763_geom ON od_77763\n       USING gist(geometry);\nCREATE INDEX idx_od_77763_id on weighted_sampling\n       USING btree(id);\nCREATE INDEX idx_od_77763_geom_build on weighted_sampling \n       USING btree(\"build\");\n---- The current total is 77763\n\n\n\n\nShow the code\nCREATE TABLE od_40420_snapped_origin AS\nSELECT DISTINCT ON (net.id)\n       pt.id AS pt_id,\n       net.id AS net_id,\n       net.the_geom\nFROM \n(select * \nFROM \n    od_77763 as pt) as pt\nCROSS JOIN\nLATERAL (SELECT\n        * \n        FROM porto_alegre_net_largest_vertices_pgr AS net\n         ORDER BY net.the_geom &lt;-&gt; pt.geometry \n        LIMIT 1) AS net;\n\n\n\n\nShow the code\nCREATE TABLE od_40420_snapped_destination AS\nSELECT DISTINCT ON (net.id)\n       pt.id AS pt_id,\n       net.id AS net_id,\n       net.the_geom\nFROM \n(select * \nFROM \n    od_77763 as pt) as pt\nCROSS JOIN\nLATERAL (SELECT\n        * \n        FROM porto_alegre_net_largest_vertices_pgr AS net\n         ORDER BY net.the_geom &lt;-&gt; pt.geometry \n        LIMIT 1) AS net;\n\n\n\n\n2.5.1.3 Hospitals\n\n\nShow the code\n--- Create a table with the bounding box that contains Porto Alegre + GHS\nCREATE TABLE porto_alegre_bbox AS\nWITH porto_alegre_ghs AS(\n    SELECT \n       ghs.*\n    FROM\n       urban_center_4326 AS ghs\n    JOIN\n       nuts \n    ON \n       st_intersects(nuts.geom, ghs.geom)\n    WHERE \n        nuts.shapename = 'Porto Alegre'),\n--- Bounding Box that contained the GHS in Porto Alegre\nporto_alegre_ghs_bbox AS(\n    SELECT \n        st_setsrid(st_extent(geom),4326) as geom_bbox\n    FROM \n        porto_alegre_ghs)\n SELECT * FROM porto_alegre_ghs_bbox \n---Use the bounding box to select hospitals\nCREATE TABLE hospital_rs_node_v2 AS\nWITH hospital_rs_porto AS (\nSELECT \n    h.*\nFROM \n    hospitals_bed_rs AS h,\n    porto_alegre_bbox bbox\nWHERE st_intersects(h.geom, bbox.geom_bbox))\nSELECT DISTINCT ON (h.cd_cnes)\n    cd_cnes,\n    ds_cnes,\n    f.id,\n    f.the_geom &lt;-&gt; h.geom AS distance,\n    h.geom AS geom_hospital,\n    f.the_geom AS geom_node\nFROM hospital_rs_porto h\nLEFT JOIN LATERAL\n(SELECT \n    id, \n    the_geom\nFROM porto_alegre_net_largest_vertices_pgr AS net\nORDER BY\n    net.the_geom &lt;-&gt; h.geom\nLIMIT 1) AS f ON true\n\n---- Create index to optimize fuerther queries\n\nCREATE INDEX idx_hospital_rs_node_v2 ON hospital_rs_node_v2 USING btree(id);\n\n\n\n\n\n2.5.2 Centrality Analysis:\n\n\nShow the code\n--- Pre-scenario\n CREATE TABLE centrality_100_100_dijkstra AS\n SELECT   b.id,\n b.the_geom,\n count(the_geom) as centrality \n FROM  pgr_dijkstra('SELECT  id,\n                             source,\n                            target,\n                            cost\n                      FROM porto_alegre_net_largest',\n                      ARRAY(SELECT net_id AS start_id FROM weight_sampling_100_origin  ),\n                      ARRAY(SELECT net_id AS end_id FROM weight_sampling_100_destination ),\n                      directed := TRUE) j\n                      left JOIN porto_alegre_street_united AS b\n                      ON j.edge = b.id\n                      GROUP BY  b.id, b.the_geom\n                      ORDER BY centrality DESC;  \n                      \n                     \n                     select * from porto_alegre_net_largest ;\n---- Adding the bidirectid by joining the dijkstra table with the original\nCREATE TABLE centrality_weighted_100_bidirect AS\nSELECT t1.*,\n    t2.\"bidirectid\"\nFROM\n    centrality_100_100_dijkstra t1\nJOIN\n    porto_alegre_net_largest t2\nON\n    t1.id = t2.id;\n--- The final product requries  79941\nselect max(\"bidirectid\") from centrality_weighted_100_bidirect;\ncreate sequence bididirect_id_weight start 79941;\nupdate centrality_weighted_100_bidirect\nset \"bidirectid\" = nextval('bididirect_id_weight')\nwhere \"bidirectid\" is null ;\n---- verify\nselect count(*) \nfrom centrality_weighted_100_bidirect \nwhere \"bidirectid\" is null; --- 0\n----\ncreate table centrality_weighted_100_bidirect_group as \nselect \n       \"bidirectid\",\n       sum(centrality) as  centrality\nfrom centrality_weighted_100_bidirect\ngroup by \"bidirectid\"; --- this sum the centrality for duplicated bidirect id\n---\n---- now recover the id\ncreate table centrality_weighted_100_bidirect_group_id as \nselect t1.*, t2.id\nfrom centrality_weighted_100_bidirect_group t1\njoin centrality_weighted_100_bidirect t2 \non t1.\"bidirectid\" = t2.\"bidirectid\"; \n---- add geometries\ncreate table centrality_weighted_100_bidirect_cleaned as\nselect t1.*,\n    t2.the_geom,\n    t2.target,\n    t2.source,\n    t2.cost,\n    t2.\"unidirectid\"\nfrom \n    centrality_weighted_100_bidirect_group_id t1\njoin\n    porto_alegre_net_largest t2\non\n    t1.id = t2.id;\n--- The final product is: centrality_weighted_100_bidirect_cleaned\n\n\n\n\nShow the code\n--- Post scenario\n\n----routing\n CREATE TABLE centrality_100_100_dijkstra_post AS\n SELECT   b.id,\n b.the_geom,\n count(the_geom) as centrality \n FROM  pgr_dijkstra('SELECT  id,\n                             source,\n                            target,\n                            cost\n                      FROM prueba_largest_network_post',\n                      ARRAY(SELECT net_id AS start_id FROM weight_sampling_100_origin_post  ),\n                      ARRAY(SELECT net_id AS end_id FROM weight_sampling_100_destination_post ),\n                      directed := TRUE) j\n                      left JOIN prueba_largest_network_post AS b\n                      ON j.edge = b.id\n                      GROUP BY  b.id, b.the_geom\n                      ORDER BY centrality DESC;  \n---- Adding the bidirectid by joining the dijkstra table with the original\nCREATE TABLE centrality_weighted_100_bidirect_post AS\nSELECT t1.*,\n    t2.\"bidirectid\"\nFROM\n    centrality_100_100_dijkstra_post t1\nJOIN\n    prueba_largest_network_post t2\nON\n    t1.id = t2.id;\n--- The final product requries  79918\nselect max(\"bidirectid\") from centrality_weighted_100_bidirect_post; ---79918\ncreate sequence bididirect_id_weight_post start 79918;\nupdate centrality_weighted_100_bidirect_post\nset \"bidirectid\" = nextval('bididirect_id_weight_post')\nwhere \"bidirectid\" is null ;\n   ---- verify\nselect count(*) \nfrom centrality_weighted_100_bidirect_post \nwhere \"bidirectid\" is null; --- 0              \n----\ncreate table centrality_weighted_100_bidirect_group_post as \nselect \n       \"bidirectid\",\n       sum(centrality) as  centrality\nfrom centrality_weighted_100_bidirect_post\ngroup by \"bidirectid\"; --- this sum the centrality for duplicated bidirect id\n---        \n---- now recover the id\ncreate table centrality_weighted_100_bidirect_group_post_id as \nselect t1.*, t2.id\nfrom centrality_weighted_100_bidirect_group_post t1\njoin centrality_weighted_100_bidirect_post t2 \non t1.\"bidirectid\" = t2.\"bidirectid\"; \n---- add geometries\ncreate table centrality_weighted_100_bidirect_cleaned_post as\nselect t1.*,\n    t2.the_geom,\n    t2.target,\n    t2.source,\n    t2.cost,\n    t2.\"unidirectid\"\nfrom \n    centrality_weighted_100_bidirect_group_post_id t1\njoin\n    prueba_largest_network_post t2\non\n    t1.id = t2.id;       \n\n\n\n2.5.2.1 Edge betweenness\n\n\nShow the code\nCREATE TABLE od_40420_snapped_origin AS\nSELECT DISTINCT ON (net.id)\n       pt.id AS pt_id,\n       net.id AS net_id,\n       net.the_geom\nFROM \n(select * \nFROM \n    od_77763 as pt) as pt\nCROSS JOIN\nLATERAL (SELECT\n        * \n        FROM porto_alegre_net_largest_vertices_pgr AS net\n         ORDER BY net.the_geom &lt;-&gt; pt.geometry \n        LIMIT 1) AS net;\n\n\n\n\nShow the code\nCREATE TABLE random_272_destination  AS\nwith random_272_destination AS (\n        SELECT\n            * \n        FROM \n            od_40420_snapped_origin \n        ORDER BY random() LIMIT 200)\n        SELECT * FROM  random_272_destination;  \n\n\n\n\nShow the code\nCREATE TEMP TABLE vertices_lookup_v5 \nAS             \nWITH all_pairs AS (\n  SELECT f.net_id AS fid, f.the_geom as fgeom,\n         t.net_id AS tid, t.the_geom as tgeom\n    FROM random_272_origin AS f,\n         random_272_destination AS t\n),\nvertices AS (\n  SELECT fid, tid,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; fgeom\n       LIMIT 1) as fv,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; tgeom\n       LIMIT 1) as tv\n  FROM all_pairs\n)\nSELECT * FROM vertices;\n\n\n\n\nShow the code\nCREATE TABLE porto_272_272_dijkstra AS\n WITH pgr_result AS (\n   SELECT pgr_dijkstra('SELECT id,\n           source,\n    target,\n     cost FROM porto_alegre_net_largest',\n     array_agg(fv), array_agg(tv), \n     directed := true\n   ) FROM vertices_lookup_v5\n )\nSELECT (pgr_dijkstra).*, a.fid, a.tid FROM pgr_result\nJOIN vertices_lookup_v5 a\nON (pgr_dijkstra).start_vid = a.fv\nAND (pgr_dijkstra).end_vid = a.tv;\n\n\n\n\nShow the code\nCREATE TEMP TABLE vertices_lookup_v5                     \nAS             \nWITH all_pairs AS (\n  SELECT f.net_id AS fid, f.the_geom as fgeom,\n         t.net_id AS tid, t.the_geom as tgeom\n    FROM random_272_origin AS f,                                                                      \n         random_272_destination AS t               \n),                                                                                     \nvertices AS (\n  SELECT fid, tid,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; fgeom\n       LIMIT 1) as fv,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; tgeom\n       LIMIT 1) as tv\n  FROM all_pairs\n)\nSELECT * FROM vertices;\n\n\n\n\nShow the code\n\nCREATE TEMP TABLE vertices_lookup_v5                     \nAS             \nWITH all_pairs AS (\n  SELECT f.net_id AS fid, f.the_geom as fgeom,\n         t.net_id AS tid, t.the_geom as tgeom\n    FROM random_272_origin AS f,                                                                      \n         random_272_destination AS t               \n),                                                                                     \nvertices AS (\n  SELECT fid, tid,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; fgeom\n       LIMIT 1) as fv,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; tgeom\n       LIMIT 1) as tv\n  FROM all_pairs\n)\nSELECT * FROM vertices;\n\n\n\n\n2.5.2.2 Closeness\n\n\nShow the code\nCREATE TABLE clossness_hospital_porto AS \nWITH dijkstra_cost AS (\nSELECT * FROM pgr_dijkstraCostMatrix(\n  'SELECT id, source, target, cost FROM porto_alegre_net_largest',\n  (SELECT array_agg(id)\n    FROM porto_alegre_net_largest_vertices_pgr\n    WHERE id IN (SELECT id FROM hospital_rs_node_v3)),\n  true)),\ncloseness AS (\n SELECT dc.start_vid,\n        sum(agg_cost)::int AS closeness\nFROM dijkstra_cost dc\nGROUP BY dc.start_vid\nORDER BY closeness DESC)\nSELECT \n    h.cd_cnes,\n    h.ds_cnes,\n    c.closeness,\n    h.distance,\n    h.geom_node,\n    h.geom_hospital\nFROM \n    closeness AS c\nLEFT JOIN\n    hospital_rs_node_v3 AS h ON  c.start_vid = h.id;\n\n\n\n\n2.5.2.3 Vulnerability: Socioeconomic indicators\n\n\n2.5.2.4 Resiliance:"
  },
  {
    "objectID": "results.html#preparation",
    "href": "results.html#preparation",
    "title": "3  Results",
    "section": "3.1 Preparation",
    "text": "3.1 Preparation\nThe code ?lst-ghs-osmium covered the following area:\n\n\nShow the code\n# Osmium command\nosmium extract -b -51.2791,-30.1722,-50.9407,-29.8048 sul-240501.osm.pbf -o puerto_alegre_urban_center.osm.pbf"
  },
  {
    "objectID": "results.html#framework",
    "href": "results.html#framework",
    "title": "3  Results",
    "section": "3.2 Framework",
    "text": "3.2 Framework"
  },
  {
    "objectID": "results.html#osm-ors",
    "href": "results.html#osm-ors",
    "title": "3  Results",
    "section": "3.3 OSM & ORS",
    "text": "3.3 OSM & ORS\n\n\nShow the code\n# Load data\nors_network &lt;- st_read(eisenberg_connection, layer=\"porto_alegre_net_pre\")\nosm_network &lt;- st_read(eisenberg_connection, layer=\"puerto_alegre_ghs_osm\")\nors_network_subset &lt;- ors_network |&gt; head()\n## Create subset using a bounding box\nors_subset &lt;- ors_network |&gt; filter(id ==140210) |&gt; st_bbox()\nxrange &lt;- ors_subset$xmax - ors_subset$xmin\nyrange &lt;- ors_subset$ymax - ors_subset$ymin\n## Expand the bounding box\nors_subset[1] &lt;- ors_subset[1] - (4 * xrange) # xmin - left\nors_subset[3] &lt;- ors_subset[3] + (4 * xrange) # xmax - right\nors_subset[2] &lt;- ors_subset[2] - (2 * yrange) # ymin - bottom\nors_subset[4] &lt;- ors_subset[4] + (2 * yrange) # ymax - top\n## Convert bounding box into polygon\nors_subset_bbox &lt;- ors_subset %&gt;%  # \n  st_as_sfc() \n## Use the polygon to subset the network\nintersection_ors &lt;- sf::st_intersection(ors_network, ors_subset_bbox)\nintersection_osm &lt;- sf::st_intersection(osm_network, ors_subset_bbox)\n## Mapview maps\nm1 &lt;- mapview(intersection_osm, \n              color=\"#6e93ff\",\n              layer.name =\"OpenStreetMap - Geometry\",\n              popup=popupTable(intersection_osm, \n                               zcol=c(\"id\",\"osm_id\",\"name\",\"geom\")))\nm2 &lt;- mapview(intersection_ors,\n              color =\"#d50038\",\n              layer.name=\"OpenRouteService -Graph\",\n              popup=popupTable(intersection_ors))\n\nsync(m1,m2)"
  },
  {
    "objectID": "results.html#sampling-points",
    "href": "results.html#sampling-points",
    "title": "3  Results",
    "section": "3.2 Sampling points",
    "text": "3.2 Sampling points\n\n\nShow the code\n# Crop and Reproject\n# gdalwarp -te -4850853.201784615 -3737074.296348413 -4616291.881935796 -3495378.804761388 GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0.tif GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V\n# gdalwarp -t_srs \"EPSG:4326\" GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0_RioGrandeDoSul.tif GHS_BUILT_V_E2020_GLOBE_R2023A_4326_100_V1_0_RioGrandeDoSul.tif\npal &lt;- mapview::mapviewPalette(\"mapviewTopoColors\")\nghs_build &lt;- stack(\"/home/ricardo/heigit_bookdown/data/GHS_BUILT_V_E2020_GLOBE_R2023A_4326_100_V1_0_RioGrandeDoSul.tif\") \nghs_smod &lt;- stack(\"/home/ricardo/heigit_bookdown/data/GHS_SMOD_E2020_GLOBE_R2023A_4326_1000_V2_0_RioGrandeDoSul.tif\")\nghs_smod_terra &lt;- terra::rast(\"/home/ricardo/heigit_bookdown/data/GHS_SMOD_E2020_GLOBE_R2023A_4326_1000_V2_0_RioGrandeDoSul.tif\")\nregular_sampling &lt;- st_read(\"/home/ricardo/heigit_bookdown/data/random_points_snapped.geojson\")\n\n\nReading layer `random_points_snapped' from data source \n  `/home/ricardo/heigit_bookdown/data/random_points_snapped.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1207 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -51.27878 ymin: -30.17215 xmax: -50.94488 ymax: -29.80879\nGeodetic CRS:  WGS 84\n\n\nShow the code\nweighted_sampling_origin &lt;- st_read(eisenberg_connection,\"weight_sampling_100_origin\")\nweighted_sampling_destination &lt;- st_read(eisenberg_connection,\"weight_sampling_100_destination\")\nm &lt;- matrix(c(\n     0, 10, NA,   # Values &gt;= 0 and &lt;= 10 become 0\n     10, 13, 1,  # Values &gt; 10 and &lt;= 21 become 1\n     13, 29, 2,  # Values &gt; 21 and &lt;= 29 become 2\n     30, 30, 3   # Values == 30 become 3\n ), ncol = 3, byrow = TRUE)\n \n# Classify using the correct matrix\nrc2 &lt;- classify(ghs_smod_terra, m, include.lowest=TRUE)\nrc2_factor &lt;- as.factor(rc2)\nlevels(rc2_factor) &lt;- data.frame(\n  ID = 1:3,    # These should match the values in the classification\n  category = c(\"Rural: 10-13\", \"Suburban: 13-29\", \"Urban Center: 30\")\n)\ncategory_colors &lt;- c(\"#008f44\",\"#dedb96\", \"#cc9152\")\n# mapview(rc2_factor, \n#        na.color=\"transparent\",\n#        col.regions = category_colors,  # Apply colors to categories\n#        legend = TRUE,                  # Show legend\n#        layer.name = \"Settlement Typologies\")\n\nmapview(ghs_build[[1]],layer.name =\"Built-up volume\", col.regions = pal(100), legend = TRUE, alpha.regions= 0.35, hide=FALSE) +\nmapview(ghs_smod[[1]], layer.name = \"Settlement classification\", col.regions = pal(100), legend = TRUE, alpha.regions= 0.35, hide=TRUE) +\nmapview(weighted_sampling_origin, layer.name=\"\" ,color=\"blue\",col.regions = \"blue\", hide=FALSE) +\nmapview(weighted_sampling_destination, color=\"red\",col.regions = \"red\", hide=FALSE)  +\nmapview(regular_sampling, color = \"darkgray\", col.regions=\"darkgray\", hide=TRUE) \n\n\nWarning in rasterCheckSize(x, maxpixels = maxpixels): maximum number of pixels for Raster* viewing is 5e+05 ; \nthe supplied Raster* has 9591546 \n ... decreasing Raster* resolution to 5e+05 pixels\n to view full resolution set 'maxpixels =  9591546 '"
  },
  {
    "objectID": "results.html#network",
    "href": "results.html#network",
    "title": "3  Results",
    "section": "3.3 Network",
    "text": "3.3 Network\n\n3.3.1 Post-event\n\n\nShow the code\n--- pre_net_subset\nCREATE TABLE porto_alegre_net_largest_subset AS                  \nSELECT\n  *\nFROM \n  porto_alegre_net_largest AS net\nWHERE \nnet.the_geom && \nst_setsrid(\n            st_makeenvelope(\n              -51.214287,-30.020226,-51.12934,-29.945862),4326)\n--- subset_network_in\n\n------------- network inside\n\nCREATE TEMPORARY TABLE flooding_subdivided_porto_join AS\nSELECT st_union(the_geom) AS the_geom FROM flooding_subdivided_porto ;\n\n----\nCREATE TABLE porto_alegre_street_in_v3 AS\nSELECT net.id,\n    CASE \n        WHEN ST_Contains(flood.the_geom, net.the_geom)\n        THEN net.the_geom\n        ELSE st_intersection(net.the_geom, flood.the_geom)\n    END AS  geom\nFROM porto_alegre_net_largest_subset net\nJOIN flooding_subdivided_porto_join flood\nON st_intersects(net.the_geom, flood.the_geom);         \n\n--- subset_network_out\nCREATE TABLE porto_alegre_street_out_v3 AS\nSELECT net.*\nFROM porto_alegre_net_largest_subset\nWHERE net.id NOT IN (\n    SELECT net.id\n    FROM porto_alegre_street_in_v3 net);\n    \n---- network outside\n\nCREATE TABLE porto_alegre_net_outside_v3 AS\nWITH porto_alegre_ghs AS(\n    SELECT \n       ghs.*\n    FROM\n       urban_center_4326 AS ghs\n    JOIN\n       nuts \n    ON \n       st_intersects(nuts.geom, ghs.geom)\n    WHERE \n        nuts.shapename = 'Porto Alegre'),\n--- Bounding Box that contained the GHS in Porto Alegre\nporto_alegre_ghs_bbox AS(\n    SELECT \n        st_setsrid(st_extent(geom),4326) as geom_bbox\n    FROM \n        porto_alegre_ghs),\nflooding_sul_subdivided AS (\n        SELECT \n            st_subdivide(geom) as the_geom\n        FROM\n            flooding_rio_grande_do_sul),\nexterior_ring_porto_alegre_v2 AS (\nSELECT \n    ST_ExteriorRing((ST_Dump(union_geom)).geom) as geom\nFROM (\n    SELECT \n        ST_Union(flood.the_geom) as union_geom\n    FROM \n        porto_alegre_ghs_bbox as bbox\n    JOIN \n        flooding_sul_subdivided as flood\n    ON \n        ST_Intersects(flood.the_geom, bbox.geom_bbox)\n) AS subquery)\nSELECT net.id,\n    CASE\n        WHEN NOT ST_Contains(flood.geom, net.the_geom)\n        THEN net.the_geom\n            ELSE st_intersection(net.the_geom, flood.geom)\n    END AS  geom,\n    net.target,\n       net.source,\n       cost,\n       \"unidirectid\",\n       \"bidirectid\"\nFROM\nporto_alegre_net_largest_subset AS net\nJOIN exterior_ring_porto_alegre_v2 flood ON\nst_intersects(net.the_geom, flood.geom)\nWHERE \n  net.the_geom && \n    st_setsrid(\n    st_makeenvelope(-51.214287,-30.020226,-51.12934,-29.945862),4326);\n----\n--- For the network\nCREATE INDEX idx_porto_alegre_net_outside_v2 ON porto_alegre_net_outside_v2 USING gist (geom);\n\nCLUSTER porto_alegre_net_outside_v2 USING idx_porto_alegre_net_outside_v2;\n\n--- For the flooding mask\nCREATE INDEX flooding_sul_subdivided_idx ON flooding_sul_subdivided USING gist (the_geom);\n\nCLUSTER flooding_sul_subdivided USING flooding_sul_subdivided_idx;\n\n---- Before doing difference\nVACUUM(FULL, ANALYZE) porto_alegre_net_outside_v2;\nVACUUM(FULL, ANALYZE) flooding_sul_subdivided;\n----\nCREATE INDEX idx_porto_alegre_net_outside_v3 ON porto_alegre_net_outside_v3 USING gist (geom);\n\nCLUSTER porto_alegre_net_outside_v3 USING idx_porto_alegre_net_outside_v3;\n\n--- For the flooding mask\nCREATE INDEX flooding_subdivided_porto_join_idx ON flooding_subdivided_porto_join USING gist (the_geom);\n\nCLUSTER flooding_subdivided_porto_join USING flooding_subdivided_porto_join_idx ;\n\n---- Before doing difference\nVACUUM(FULL, ANALYZE) porto_alegre_net_outside_v3;\nVACUUM(FULL, ANALYZE) flooding_subdivided_porto_join;\n\n----\n\nCREATE TABLE flooding_symple as \nSELECT st_union(geom) as the_geom FROM flooding_cleaned_porto_union_simple;\n\nCREATE INDEX flooding_symple_idx ON flooding_symple USING gist (the_geom);\nCLUSTER flooding_symple USING flooding_symple_idx;\n\nCREATE TABLE difference_outside_flood_v4 AS\nSELECT net.id,\n        target,\n        source,\n        cost,\n        unidirectid,\n        bidirectid,\nst_difference(net.geom, flood.the_geom) AS the_geom\nFROM porto_alegre_net_outside_v3 AS net,\nflooding_symple  AS flood;\n\n-----------\nCREATE TABLE porto_alegre_street_united_v3 AS\nSELECT *\nFROM porto_alegre_street_out_v3\nUNION\nSELECT *\nFROM difference_outside_flood_v4;\n\n--- Final product: porto_alegre_street_united_v2\n\n\n\n\nShow the code\n\nCREATE TABLE subset_post_scenario_bbox AS\nSELECT st_setsrid(\n            st_makeenvelope(\n              -51.214287,-30.020226,-51.12934,-29.945862),4326) AS geom;\n\n\n\n\nShow the code\n\n---- Generate the subset to be visualize\n\nCREATE TABLE porto_alegre_net_largest_subset AS                  \nSELECT\n  st_intersection(net.the_geom, bbox.geom) \nFROM \n  porto_alegre_net_largest AS net\nWHERE \nporto_alegre_net_largest.the_geom && subset_post_scenario_bbox; \n\n\n\n\nShow the code\nSELECT\n  st_intersection(net.the_geom, bbox.geom)\nFROM \n  porto_alegre_net_largest AS net,\nsubset_post_scenario_bbox AS bbox;\n\n\n\n\n3.3.2 Performance\n\n\nShow the code\nlibrary(readODS)\nlibrary(ggplot2)\nperformance &lt;- readODS::read_ods(\"metrics.ods\")\ndf &lt;- performance |&gt; dplyr::select(c(\"number_od\",\"method\",\"algorithm\",\"time\",\"max_centrality\",\"count_rows\")) |&gt; filter(!is.na(time) & method=='naive')\n\nggplot(df,aes(x=number_od, y=time, group = algorithm)) +\n  geom_line(aes(color=algorithm)) +\n   geom_point(aes(color=algorithm))\n\n\n\n\n\nShow the code\nDT::datatable(subset(df, select=c(\"number_od\",\"algorithm\",\"time\")), \n              class='compact', rownames=FALSE, escape=FALSE, caption='Data description',\n              extensions=c(\"Buttons\",'RowGroup'),\n              options=list(\n                  order=list(list(0, 'asc'), list(2,'asc')),  # Sort by the first column (index 0)\n                  rowGroup=list(dataSrc=0),    # Fixed rowGroup\n                  dom=\"Bfrtip\",\n                  buttons=c(\"copy\", \"csv\", \"pdf\"),\n                  initComplete = JS(\n                      \"function(settings, json) {\",\n                      \"$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});\",\n                      \"}\")\n              )\n) |&gt; \n    DT::formatStyle(\"time\",\n                    background=DT::styleColorBar(range(df$time), '#ee8b8b'),\n                    backgroundSize='98% 88%',\n                    backgroundRepeat='no-repeat',\n                    backgroundPosition='center')\n\n\n\n\n\n\n\n\n\n3.3.3 Centrality\n\n\nShow the code\ncentrality_pre &lt;- st_read(eisenberg_connection, \"centrality_weighted_100_bidirect_cleaned\")\n\n\n\n\n3.3.4 Closeness\n\n\nShow the code\nclosseness &lt;-sf::st_read(eisenberg_connection, \n                            layer = \"clossness_hospital_porto\")\nclosseness_no_geom &lt;- closseness |&gt;  \n                          arrange(ds_cnes, closeness) |&gt;\n                          mutate(lng= \n                              unlist(map(geom_hospital,1)),\n                           lat=\n                              unlist(map(geom_hospital,2)),\n                           closeness_norm = \n                          (closseness$closeness - min(closseness$closeness)) / (max(closseness$closeness) - min(closseness$closeness)) * 100,\n                          position = rank(-closeness),\n                          ds_cnes =stringr::str_to_title(ds_cnes)) |&gt;\n                  sf::st_drop_geometry()\n\nDT::datatable(subset(closseness_no_geom, select=c(\"position\",\"cd_cnes\",\"ds_cnes\",\"closeness\")),\n              extensions=\"Buttons\",\n                         options=list(\n                           dom=\"Bfrtip\",\n                           buttons=c(\"copy\",\"csv\",\"pdf\"),\n                            initComplete = JS(\n    \"function(settings, json) {\",\n    \"$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});\",\n    \"}\")\n                                  )\n              ) |&gt; \n    DT::formatStyle(\"closeness\",\n              background=DT::styleColorBar(range(closseness_no_geom$closeness),'#ee8b8b'),\n                backgroundSize = '98% 88%',\n  backgroundRepeat = 'no-repeat',\n  backgroundPosition = 'center') \n\n\n\n\n\n\n\n\n\nShow the code\n# Import he data\n## hospital with closenesss values\nclosseness &lt;-sf::st_read(eisenberg_connection, \n                            layer = \"clossness_hospital_porto\")\nclosseness_df &lt;- closseness |&gt;  arrange(ds_cnes, closeness) |&gt;\n                    mutate(lng= \n                              unlist(map(geom_hospital,1)),\n                           lat=\n                              unlist(map(geom_hospital,2)),\n                           closeness_norm = \n                          (closseness$closeness - min(closseness$closeness)) / (max(closseness$closeness) - min(closseness$closeness)) * 100,\n                          position = rank(-closeness))\n## Create Color palette for visualization\npal &lt;- colorQuantile(palette = \"OrRd\",closseness_df$closeness, n=4 )\n\n## Create leaflet product\n\nicons &lt;- makeAwesomeIcon(\n  icon = 'fa-heartbeat',\n  iconColor = \"#FFFFFF\",\n  markerColor = \"#57142c\",\n  library = \"fa\"\n)\nleaflet(closseness_df) |&gt;\n    addProviderTiles(providers$OpenStreetMap.HOT) |&gt;\n    addCircles(data =closseness_df , radius = ~sqrt(closeness)*10, fillOpacity = .50, color =~pal(closeness)) |&gt;\n  addAwesomeMarkers(data=closseness_df,\n                          icon =icons,\n                          popup= ~paste0(\"&lt;b&gt;Código CNES: &lt;/b&gt;\", cd_cnes, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt;Nome: &lt;/b&gt;\", ds_cnes, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt; Closeness&lt;/b&gt;:\", closeness, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt;Longitude: &lt;/b&gt;\", lng, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt;Posição &lt;/b&gt;\", position, \"&lt;br/&gt;\"))"
  },
  {
    "objectID": "conclussion.html#framework",
    "href": "conclussion.html#framework",
    "title": "4  Conclussion",
    "section": "4.1 Framework",
    "text": "4.1 Framework"
  },
  {
    "objectID": "conclussion.html#data",
    "href": "conclussion.html#data",
    "title": "4  Conclussion",
    "section": "4.2 Data",
    "text": "4.2 Data"
  },
  {
    "objectID": "conclussion.html#sampling-points",
    "href": "conclussion.html#sampling-points",
    "title": "4  Conclussion",
    "section": "4.3 Sampling points",
    "text": "4.3 Sampling points"
  },
  {
    "objectID": "conclussion.html#network",
    "href": "conclussion.html#network",
    "title": "4  Conclussion",
    "section": "4.4 Network",
    "text": "4.4 Network"
  },
  {
    "objectID": "future_work.html#point-of-interest",
    "href": "future_work.html#point-of-interest",
    "title": "5  Future work & suggestions",
    "section": "5.1 Point of interest",
    "text": "5.1 Point of interest"
  },
  {
    "objectID": "future_work.html#perforamance",
    "href": "future_work.html#perforamance",
    "title": "5  Future work & suggestions",
    "section": "5.2 Perforamance",
    "text": "5.2 Perforamance\n\n5.2.1 Flood mask\nUsing the dilate and erode method described in the slide 95/187 (link) could remove small islands that increase the computational costs. A use case of this technique is observed when simplifying coastlines (link)"
  },
  {
    "objectID": "future_work.html#data",
    "href": "future_work.html#data",
    "title": "5  Future work & suggestions",
    "section": "5.3 Data",
    "text": "5.3 Data"
  },
  {
    "objectID": "future_work.html#sampling-points",
    "href": "future_work.html#sampling-points",
    "title": "5  Future work & suggestions",
    "section": "5.4 Sampling points",
    "text": "5.4 Sampling points"
  },
  {
    "objectID": "future_work.html#network",
    "href": "future_work.html#network",
    "title": "5  Future work & suggestions",
    "section": "5.5 Network",
    "text": "5.5 Network"
  },
  {
    "objectID": "appendix.html#section",
    "href": "appendix.html#section",
    "title": "6  Performance tests",
    "section": "6.1 10",
    "text": "6.1 10\n#| eval: false"
  },
  {
    "objectID": "appendix.html#section-1",
    "href": "appendix.html#section-1",
    "title": "6  Performance tests",
    "section": "6.2 50",
    "text": "6.2 50\n#| eval: false"
  },
  {
    "objectID": "appendix.html#section-2",
    "href": "appendix.html#section-2",
    "title": "6  Performance tests",
    "section": "6.3 100",
    "text": "6.3 100\n#| eval: false"
  },
  {
    "objectID": "appendix.html#section-3",
    "href": "appendix.html#section-3",
    "title": "6  Performance tests",
    "section": "6.4 200",
    "text": "6.4 200\n#| eval: false\n---- Create 200 origin\nCREATE TABLE sampling_weight_200_origin  AS\nwith porto_200_origin AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped_origin \n        ORDER BY random() LIMIT 200)\n        SELECT * FROM  porto_200_origin;  \n---- Create 200 destination\nCREATE TABLE sampling_weight_200_destination  AS\nwith porto_200_destination AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped_origin \n        ORDER BY random() LIMIT 200)\n        SELECT * FROM  porto_200_destination;  \n---- Create index for origin\nCREATE INDEX idx_sampling_weight_200_origin_net_id ON sampling_weight_200_origin USING hash(net_id);\nCREATE INDEX idx_sampling_weight_200_origin_geom ON sampling_weight_200_origin USING gist(the_geom);\n---- Create index for destination\nCREATE INDEX idx_sampling_weight_200_destination_net_id ON sampling_weight_200_destination USING hash(net_id);\nCREATE INDEX idx_sampling_weight_200_destination_geom ON sampling_weight_200_destination USING gist(the_geom);\n---- Cluster\nCLUSTER porto_alegre_net_largest USING idx_porto_alegre_net_largest_geom;\n---- Vacuum clean\nVACUUM(full, ANALYZE) sampling_weight_200_origin;\nVACUUM(full, ANALYZE) sampling_weight_200_destination;\nVACUUM(full, ANALYZE) porto_alegre_net_largest;\n--- Run query\n\nEXPLAIN ANALYZE\n CREATE TABLE centrality_200_200_porto AS\n SELECT   b.ogc_fid,\n b.the_geom,\n count(the_geom) as centrality \n FROM  pgr_dijkstra('SELECT  ogc_fid AS id,\n                              fromid AS source,\n                            toid AS target,\n                            weight AS cost\n                      FROM porto_alegre_net_largest',\n                      ARRAY(SELECT net_id AS start_id FROM porto_200_origin  ),\n                      ARRAY(SELECT net_id AS end_id FROM porto_200_destination ),\n                      directed := TRUE) j\n                      left JOIN porto_alegre_net_largest AS b\n                      ON j.edge = b.ogc_fid\n                      GROUP BY  b.ogc_fid, b.the_geom\n                      ORDER BY centrality DESC;"
  },
  {
    "objectID": "appendix.html#section-4",
    "href": "appendix.html#section-4",
    "title": "6  Performance tests",
    "section": "6.5 300",
    "text": "6.5 300\n#| eval:  false\n\n\n---- 300\n\n---- Create 300 origin\nCREATE TABLE sampling_weight_300_origin  AS\nwith porto_300_origin AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped_origin \n        ORDER BY random() LIMIT 300)\n        SELECT * FROM  porto_300_origin;  \n---- Create 300 destination\nCREATE TABLE sampling_weight_300_destination  AS\nwith porto_300_destination AS (\n        SELECT\n            * \n        FROM \n            od_2728_snapped_origin \n        ORDER BY random() LIMIT 300)\n        SELECT * FROM  porto_300_destination;  \n---- Create index for origin\nCREATE INDEX idx_sampling_weight_300_origin_net_id ON sampling_weight_300_origin USING hash(net_id);\nCREATE INDEX idx_sampling_weight_300_origin_geom ON sampling_weight_300_origin USING gist(the_geom);\n---- Create index for destination\nCREATE INDEX idx_sampling_weight_300_destination_net_id ON sampling_weight_300_destination USING hash(net_id);\nCREATE INDEX idx_sampling_weight_300_destination_geom ON sampling_weight_300_destination USING gist(the_geom);\n---- Cluster\nCLUSTER porto_alegre_net_largest USING idx_porto_alegre_net_largest_geom;\n---- Vacuum clean\nVACUUM(full, ANALYZE) sampling_weight_300_origin;\nVACUUM(full, ANALYZE) sampling_weight_300_destination;\nVACUUM(full, ANALYZE) porto_alegre_net_largest;\n--- Run query\n\n EXPLAIN ANALYZE\n CREATE TABLE centrality_300_300_porto AS\n SELECT   b.ogc_fid,\n b.the_geom,\n count(the_geom) as centrality \n FROM  pgr_dijkstra('SELECT  ogc_fid AS id,\n                              fromid AS source,\n                            toid AS target,\n                            weight AS cost\n                      FROM porto_alegre_net_largest',\n                      ARRAY(SELECT net_id AS start_id FROM sampling_weight_300_origin  ),\n                      ARRAY(SELECT net_id AS end_id FROM sampling_weight_300_destination ),\n                      directed := TRUE) j\n                      left JOIN porto_alegre_net_largest AS b\n                      ON j.edge = b.ogc_fid\n                      GROUP BY  b.ogc_fid, b.the_geom\n                      ORDER BY centrality DESC;  \n                      \n--- check max centrality                     \nSELECT max(centrality) FROM centrality_300_300_porto ;\n--- check max rows\nSELECT  count(*) FROM centrality_10_10_porto;"
  },
  {
    "objectID": "appendix.html#method-array_agg",
    "href": "appendix.html#method-array_agg",
    "title": "6  Performance tests",
    "section": "6.6 Method array_agg()",
    "text": "6.6 Method array_agg()\n#| eval: false\n\n\n---- create origin_destination\nCREATE TEMP TABLE vertices_lookup_10\nAS             \nWITH all_pairs AS (\n  SELECT f.net_id AS fid, f.the_geom AS fgeom,\n         t.net_id AS tid, t.the_geom AS tgeom\n    FROM random_10_origin AS f,\n         random_10_destination AS t\n),\nvertices AS (\n  SELECT fid, tid,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; fgeom\n       LIMIT 1) AS fv,\n     (SELECT id\n        FROM porto_alegre_net_largest_vertices_pgr AS way\n       ORDER BY way.the_geom &lt;-&gt; tgeom\n       LIMIT 1) AS tv\n  FROM all_pairs\n)\nSELECT * FROM vertices;\n---- Number of OD\nSELECT count(*) FROM vertices_lookup_10;\n---- Create index\nCREATE INDEX idx_vertices_lookup_10_fid ON vertices_lookup_10 USING hash(fid);\nCREATE INDEX idx_vertices_lookup_10_tid ON vertices_lookup_10 USING hash(tid);\nCREATE INDEX idx_vertices_lookup_10_fv ON vertices_lookup_10 USING hash(fv);\nCREATE INDEX idx_vertices_lookup_10_tv ON vertices_lookup_10 USING hash(tv);\n---- Vacuum and clean\nVACUUM(full, ANALYZE) vertices_lookup_10;\nVACUUM(full, ANALYZE) porto_alegre_net_largest;\n---- Run query using array_agg()\nEXPLAIN ANALYZE\nCREATE TABLE porto_100_dijkstra_agg AS\nWITH pgr_result AS (\n  SELECT pgr_dijkstra('SELECT ogc_fid AS id,\n             fromid AS source,\n            toid AS target,\n             weight AS cost FROM porto_alegre_net_largest',\n    array_agg(fv), array_agg(tv), \n    directed := true\n  ) FROM vertices_lookup_10 \n) \nSELECT \n b.ogc_fid,\n b.the_geom,\n count(the_geom) as centrality \nFROM pgr_result\nLEFT JOIN porto_alegre_net_largest AS b\nON (pgr_dijkstra).edge = b.ogc_fid\nGROUP BY \n    the_geom, b.ogc_fid\nORDER BY \n    centrality DESC;\n---- Max centrality value\nselect max(centrality) FROM porto_100_dijkstra_agg ;\n---- Number of rows\nselect count(*) FROM porto_100_dijkstra_agg ;"
  },
  {
    "objectID": "appendix.html#pgr_astrar",
    "href": "appendix.html#pgr_astrar",
    "title": "6  Performance tests",
    "section": "6.7 pgr_astrar()",
    "text": "6.7 pgr_astrar()\n#| eval: false\n\nSELECT * FROM random_10_origin ro ;\n \nCREATE TABLE porto_alegre_net_largest_astar AS          \nWITH porto_alegre_net_astart AS (\nSELECT \n*,\nst_startpoint(the_geom) AS start_pt,\nst_endpoint(the_geom) AS end_pt\nFROM porto_alegre_net_largest AS net)\nSELECT *,\n    st_x(start_pt) AS x1,\n    st_y(start_pt) AS y1,\n    st_x(end_pt) AS x2,\n    st_y(end_pt) AS y2\nFROM porto_alegre_net_astart;\n---- adding spatial index\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_the_geom ON porto_alegre_net_largest_astar  USING gist(the_geom);\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_start ON porto_alegre_net_largest_astar  USING gist(start_pt);\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_end ON porto_alegre_net_largest_astar USING gist(end_pt);\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_x1 ON porto_alegre_net_largest_astar  USING btree(x1);\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_y1 ON porto_alegre_net_largest_astar USING btree(y1);\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_x2 ON porto_alegre_net_largest_astar USING btree(x2);\nCREATE INDEX idx_porto_alegre_net_largest_astar_net_y2 ON porto_alegre_net_largest_astar USING btree(y2);                      \n----- RUnning the query\nEXPLAIN ANALYZE\nCREATE TABLE centrality_10_10_porto_astrar AS\nSELECT  \n    b.ogc_fid,\n     b.the_geom,\n    count(the_geom) as centrality \nFROM pgr_astar(\n    'SELECT ogc_fid AS id,\n            fromid AS source,\n            toid AS target,\n            weight AS cost,\n            x1,\n            y1,\n            x2,\n            y2\n    FROM porto_alegre_net_largest_astar',\n    ARRAY(SELECT net_id FROM  random_10_origin),\n    ARRAY(SELECT net_id FROM  random_10_destination),\n             directed:=TRUE,\n             heuristic:=2) j\n                      left JOIN porto_alegre_net_largest_astar AS b\n                      ON j.edge = b.ogc_fid\n                      GROUP BY  b.ogc_fid, b.the_geom\n                      ORDER BY centrality DESC;  \n\n--- check max centrality                     \nSELECT max(centrality) FROM centrality_10_10_porto_astrar ;\n--- check max rows\nSELECT  count(*) FROM centrality_10_10_porto_astrar;"
  },
  {
    "objectID": "results.html#data-preparation",
    "href": "results.html#data-preparation",
    "title": "3  Results",
    "section": "3.1 Data preparation",
    "text": "3.1 Data preparation\n\n3.1.1 OSM & ORS data\nThe code ?lst-ghs-osmium covered the following area:\n\n\nShow the code\n# Osmium command\nosmium extract -b -51.2791,-30.1722,-50.9407,-29.8048 sul-240501.osm.pbf -o puerto_alegre_urban_center.osm.pbf\n\n\n Importing the geometries from R from Marcel\n\n\nShow the code\n# Load data\nors_network &lt;- st_read(eisenberg_connection, layer=\"porto_alegre_net_pre\")\nosm_network &lt;- st_read(eisenberg_connection, layer=\"puerto_alegre_ghs_osm\")\nors_network_subset &lt;- ors_network |&gt; head()\n## Create subset using a bounding box\nors_subset &lt;- ors_network |&gt; filter(id ==140210) |&gt; st_bbox()\nxrange &lt;- ors_subset$xmax - ors_subset$xmin\nyrange &lt;- ors_subset$ymax - ors_subset$ymin\n## Expand the bounding box\nors_subset[1] &lt;- ors_subset[1] - (4 * xrange) # xmin - left\nors_subset[3] &lt;- ors_subset[3] + (4 * xrange) # xmax - right\nors_subset[2] &lt;- ors_subset[2] - (2 * yrange) # ymin - bottom\nors_subset[4] &lt;- ors_subset[4] + (2 * yrange) # ymax - top\n## Convert bounding box into polygon\nors_subset_bbox &lt;- ors_subset %&gt;%  # \n  st_as_sfc() \n## Use the polygon to subset the network\nintersection_ors &lt;- sf::st_intersection(ors_network, ors_subset_bbox)\nintersection_osm &lt;- sf::st_intersection(osm_network, ors_subset_bbox)\n## Mapview maps\nm1 &lt;- mapview(intersection_osm, \n              color=\"#6e93ff\",\n              layer.name =\"OpenStreetMap - Geometry\",\n              popup=popupTable(intersection_osm, \n                               zcol=c(\"id\",\"osm_id\",\"name\",\"geom\")))\nm2 &lt;- mapview(intersection_ors,\n              color =\"#d50038\",\n              layer.name=\"OpenRouteService -Graph\",\n              popup=popupTable(intersection_ors))\n\nsync(m1,m2) \n\n\n\n\n3.1.2 Sampling points\n\n\nShow the code\n# Crop and Reproject\n# gdalwarp -te -4850853.201784615 -3737074.296348413 -4616291.881935796 -3495378.804761388 GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0.tif GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V\n# gdalwarp -t_srs \"EPSG:4326\" GHS_BUILT_V_E2020_GLOBE_R2023A_54009_100_V1_0_RioGrandeDoSul.tif GHS_BUILT_V_E2020_GLOBE_R2023A_4326_100_V1_0_RioGrandeDoSul.tif\npal &lt;- mapview::mapviewPalette(\"mapviewTopoColors\")\nghs_build &lt;- stack(\"/home/ricardo/heigit_bookdown/data/GHS_BUILT_V_E2020_GLOBE_R2023A_4326_100_V1_0_RioGrandeDoSul.tif\") \nghs_smod &lt;- stack(\"/home/ricardo/heigit_bookdown/data/GHS_SMOD_E2020_GLOBE_R2023A_4326_1000_V2_0_RioGrandeDoSul.tif\")\nghs_smod_terra &lt;- terra::rast(\"/home/ricardo/heigit_bookdown/data/GHS_SMOD_E2020_GLOBE_R2023A_4326_1000_V2_0_RioGrandeDoSul.tif\")\nregular_sampling &lt;- st_read(\"/home/ricardo/heigit_bookdown/data/random_points_snapped.geojson\")\n\n\nReading layer `random_points_snapped' from data source \n  `/home/ricardo/heigit_bookdown/data/random_points_snapped.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1207 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -51.27878 ymin: -30.17215 xmax: -50.94488 ymax: -29.80879\nGeodetic CRS:  WGS 84\n\n\nShow the code\nweighted_sampling_origin &lt;- st_read(eisenberg_connection,\"weight_sampling_100_origin\")\nweighted_sampling_destination &lt;- st_read(eisenberg_connection,\"weight_sampling_100_destination\")\nm &lt;- matrix(c(\n     0, 10, NA,   # Values &gt;= 0 and &lt;= 10 become 0\n     10, 13, 1,  # Values &gt; 10 and &lt;= 21 become 1\n     13, 29, 2,  # Values &gt; 21 and &lt;= 29 become 2\n     30, 30, 3   # Values == 30 become 3\n ), ncol = 3, byrow = TRUE)\n \n# Classify using the correct matrix\nrc2 &lt;- classify(ghs_smod_terra, m, include.lowest=TRUE)\nrc2_factor &lt;- as.factor(rc2)\nlevels(rc2_factor) &lt;- data.frame(\n  ID = 1:3,    # These should match the values in the classification\n  category = c(\"Rural: 10-13\", \"Suburban: 13-29\", \"Urban Center: 30\")\n)\ncategory_colors &lt;- c(\"#008f44\",\"#dedb96\", \"#cc9152\")\n# mapview(rc2_factor, \n#        na.color=\"transparent\",\n#        col.regions = category_colors,  # Apply colors to categories\n#        legend = TRUE,                  # Show legend\n#        layer.name = \"Settlement Typologies\")\n\nmapview(ghs_build[[1]],layer.name =\"Built-up volume\", col.regions = pal(100), legend = TRUE, alpha.regions= 0.35, hide=FALSE) +\nmapview(ghs_smod[[1]], layer.name = \"Settlement classification\", col.regions = pal(100), legend = TRUE, alpha.regions= 0.35, hide=TRUE) +\nmapview(weighted_sampling_origin, layer.name=\"\" ,color=\"blue\",col.regions = \"blue\", hide=FALSE) +\nmapview(weighted_sampling_destination, color=\"red\",col.regions = \"red\", hide=FALSE)  +\nmapview(regular_sampling, color = \"darkgray\", col.regions=\"darkgray\", hide=TRUE) \n\n\nWarning in rasterCheckSize(x, maxpixels = maxpixels): maximum number of pixels for Raster* viewing is 5e+05 ; \nthe supplied Raster* has 9591546 \n ... decreasing Raster* resolution to 5e+05 pixels\n to view full resolution set 'maxpixels =  9591546 '\n\n\n\n\n\n\n\n\n\n3.1.3 Network\n\n3.1.3.1 Post-event\n\n\nShow the code\n--- pre_net_subset\nCREATE TABLE porto_alegre_net_largest_subset AS                  \nSELECT\n  *\nFROM \n  porto_alegre_net_largest AS net\nWHERE \nnet.the_geom && \nst_setsrid(\n            st_makeenvelope(\n              -51.214287,-30.020226,-51.12934,-29.945862),4326)\n--- subset_network_in\n\n------------- network inside\n\nCREATE TEMPORARY TABLE flooding_subdivided_porto_join AS\nSELECT st_union(the_geom) AS the_geom FROM flooding_subdivided_porto ;\n\n----\nCREATE TABLE porto_alegre_street_in_v3 AS\nSELECT net.id,\n    CASE \n        WHEN ST_Contains(flood.the_geom, net.the_geom)\n        THEN net.the_geom\n        ELSE st_intersection(net.the_geom, flood.the_geom)\n    END AS  geom\nFROM porto_alegre_net_largest_subset net\nJOIN flooding_subdivided_porto_join flood\nON st_intersects(net.the_geom, flood.the_geom);         \n\n--- subset_network_out\nCREATE TABLE porto_alegre_street_out_v3 AS\nSELECT net.*\nFROM porto_alegre_net_largest_subset\nWHERE net.id NOT IN (\n    SELECT net.id\n    FROM porto_alegre_street_in_v3 net);\n    \n---- network outside\n\nCREATE TABLE porto_alegre_net_outside_v3 AS\nWITH porto_alegre_ghs AS(\n    SELECT \n       ghs.*\n    FROM\n       urban_center_4326 AS ghs\n    JOIN\n       nuts \n    ON \n       st_intersects(nuts.geom, ghs.geom)\n    WHERE \n        nuts.shapename = 'Porto Alegre'),\n--- Bounding Box that contained the GHS in Porto Alegre\nporto_alegre_ghs_bbox AS(\n    SELECT \n        st_setsrid(st_extent(geom),4326) as geom_bbox\n    FROM \n        porto_alegre_ghs),\nflooding_sul_subdivided AS (\n        SELECT \n            st_subdivide(geom) as the_geom\n        FROM\n            flooding_rio_grande_do_sul),\nexterior_ring_porto_alegre_v2 AS (\nSELECT \n    ST_ExteriorRing((ST_Dump(union_geom)).geom) as geom\nFROM (\n    SELECT \n        ST_Union(flood.the_geom) as union_geom\n    FROM \n        porto_alegre_ghs_bbox as bbox\n    JOIN \n        flooding_sul_subdivided as flood\n    ON \n        ST_Intersects(flood.the_geom, bbox.geom_bbox)\n) AS subquery)\nSELECT net.id,\n    CASE\n        WHEN NOT ST_Contains(flood.geom, net.the_geom)\n        THEN net.the_geom\n            ELSE st_intersection(net.the_geom, flood.geom)\n    END AS  geom,\n    net.target,\n       net.source,\n       cost,\n       \"unidirectid\",\n       \"bidirectid\"\nFROM\nporto_alegre_net_largest_subset AS net\nJOIN exterior_ring_porto_alegre_v2 flood ON\nst_intersects(net.the_geom, flood.geom)\nWHERE \n  net.the_geom && \n    st_setsrid(\n    st_makeenvelope(-51.214287,-30.020226,-51.12934,-29.945862),4326);\n----\n--- For the network\nCREATE INDEX idx_porto_alegre_net_outside_v2 ON porto_alegre_net_outside_v2 USING gist (geom);\n\nCLUSTER porto_alegre_net_outside_v2 USING idx_porto_alegre_net_outside_v2;\n\n--- For the flooding mask\nCREATE INDEX flooding_sul_subdivided_idx ON flooding_sul_subdivided USING gist (the_geom);\n\nCLUSTER flooding_sul_subdivided USING flooding_sul_subdivided_idx;\n\n---- Before doing difference\nVACUUM(FULL, ANALYZE) porto_alegre_net_outside_v2;\nVACUUM(FULL, ANALYZE) flooding_sul_subdivided;\n----\nCREATE INDEX idx_porto_alegre_net_outside_v3 ON porto_alegre_net_outside_v3 USING gist (geom);\n\nCLUSTER porto_alegre_net_outside_v3 USING idx_porto_alegre_net_outside_v3;\n\n--- For the flooding mask\nCREATE INDEX flooding_subdivided_porto_join_idx ON flooding_subdivided_porto_join USING gist (the_geom);\n\nCLUSTER flooding_subdivided_porto_join USING flooding_subdivided_porto_join_idx ;\n\n---- Before doing difference\nVACUUM(FULL, ANALYZE) porto_alegre_net_outside_v3;\nVACUUM(FULL, ANALYZE) flooding_subdivided_porto_join;\n\n----\n\nCREATE TABLE flooding_symple as \nSELECT st_union(geom) as the_geom FROM flooding_cleaned_porto_union_simple;\n\nCREATE INDEX flooding_symple_idx ON flooding_symple USING gist (the_geom);\nCLUSTER flooding_symple USING flooding_symple_idx;\n\nCREATE TABLE difference_outside_flood_v4 AS\nSELECT net.id,\n        target,\n        source,\n        cost,\n        unidirectid,\n        bidirectid,\nst_difference(net.geom, flood.the_geom) AS the_geom\nFROM porto_alegre_net_outside_v3 AS net,\nflooding_symple  AS flood;\n\n-----------\nCREATE TABLE porto_alegre_street_united_v3 AS\nSELECT *\nFROM porto_alegre_street_out_v3\nUNION\nSELECT *\nFROM difference_outside_flood_v4;\n\n--- Final product: porto_alegre_street_united_v2\n\n\n\n\nShow the code\n\nCREATE TABLE subset_post_scenario_bbox AS\nSELECT st_setsrid(\n            st_makeenvelope(\n              -51.214287,-30.020226,-51.12934,-29.945862),4326) AS geom;\n\n\n\n\nShow the code\n\n---- Generate the subset to be visualize\n\nCREATE TABLE porto_alegre_net_largest_subset AS                  \nSELECT\n  st_intersection(net.the_geom, bbox.geom) \nFROM \n  porto_alegre_net_largest AS net\nWHERE \nporto_alegre_net_largest.the_geom && subset_post_scenario_bbox; \n\n\n\n\nShow the code\nSELECT\n  st_intersection(net.the_geom, bbox.geom)\nFROM \n  porto_alegre_net_largest AS net,\nsubset_post_scenario_bbox AS bbox;"
  },
  {
    "objectID": "results.html#rq1-centrality-analysis",
    "href": "results.html#rq1-centrality-analysis",
    "title": "3  Results",
    "section": "3.2 RQ1: Centrality analysis",
    "text": "3.2 RQ1: Centrality analysis\n\nHow does road connectivity change after being impacted by flooding based on connectivity metrics?\n\n\n\nShow the code\n## create logaritmic scale\ncentrality_pre &lt;- centrality_pre |&gt; mutate(centrality_log = log10(centrality))\ncentrality_post &lt;- centrality_post |&gt; mutate(centrality_log = log10(centrality))\n### naural breaks\n#### For pre-event: 1644, 468, 142\ncentrality_pre$centrality_fct &lt;- cut(centrality_pre$centrality,\n                  breaks=c(0,142,468,1644),\n                  labels =c(\"low\",\"medium\",\"high\"),\n                  include.lowest= TRUE,\n                  right =FALSE)\n#### natural perk:  81, 230, 582\ncentrality_post$centrality_fct &lt;- cut(centrality_post$centrality,\n                  breaks=c(0,81,230,582),\n                  labels =c(\"low\",\"medium\",\"high\"),\n                  include.lowest= TRUE,\n                  right =FALSE)\n### \ncentrality_pre_map &lt;- mapview::mapview(centrality_pre,\n                                       zcol=\"centrality_fct\",\n                                        lwd =\"centrality\",\n                                       layer.name =\"Centrality Pre-Event\",\n              popup=popupTable(centrality_pre, \n                               zcol=c(\"id\",\"centrality\",\"bidirectid\"))) \ncentrality_post_map &lt;- mapview::mapview(centrality_post,\n                                       zcol=\"centrality_fct\",\n                                        lwd = \"centrality\",\n                                       layer.name =\"Centrality Post-Event\",\n              popup=popupTable(centrality_pre, \n                               zcol=c(\"id\",\"centrality\",\"bidirectid\"))) \n\ncentrality_pre_map | centrality_post_map + mapview(flooding,\n          color=\"darkblue\",\n          alpha.regions= 0.5,\n          layer.name=\"Flooding layer\")\n\n\n\n\n\nMeter tabla que incluye georefernciar\nMeter gráfica\n\n\nShow the code\nlibrary(plyr)\n\n\n------------------------------------------------------------------------------\n\n\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n\n\n------------------------------------------------------------------------------\n\n\n\nAttaching package: 'plyr'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\nShow the code\n# Tidy data and wrangling\ncentrality_post$event &lt;- \"post-flooding\"\ncentrality_pre$event &lt;- \"pre-flooding\"  \ncentrality_both &lt;- rbind(centrality_post[,c(\"id\",\"centrality\",\"event\")] ,\n                                   centrality_pre[,c(\"id\",\"centrality\",\"event\")])\nmu &lt;- plyr::ddply(centrality_both, \"event\", summarise, grp.mean=mean(centrality))\n\n# Create histogram\nggplot(centrality_both, aes(x=centrality, fill=event)) +\n                    geom_histogram(alpha=0.4,) + scale_x_log10() +\n                  labs(title = \"Centrality analysis\",\n                      subtitle= \"Histogram on log10 scale\",\n                      x = \" Betweenness centrality (centrality)\",\n                      y = \"Frequency (count)\") +\n  theme(plot.title=element_text(family =\"bold\", hjust=0.5),\n        plot.subtitle = element_text(colour=\"#626262\", hjust=0.5),\n        legend.position='bottom')\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n3.2.1 Performance\n\n\nShow the code\nlibrary(readODS)\nlibrary(ggplot2)\nperformance &lt;- readODS::read_ods(\"metrics.ods\")\ndf &lt;- performance |&gt; dplyr::select(c(\"number_od\",\"method\",\"algorithm\",\"time\",\"max_centrality\",\"count_rows\",\"query\",\"analyze\")) |&gt; filter(!is.na(time) & method=='naive')\n\nggplot(df,aes(x=number_od, y=time, group = algorithm)) +\n  geom_line(aes(color=algorithm)) +\n   geom_point(aes(color=algorithm))\n\n\n\n\n\nShow the code\nDT::datatable(subset(df, select=c(\"number_od\",\"algorithm\",\"time\",\"query\",\"analyze\")), \n              class='compact', rownames=FALSE, escape=FALSE, caption='Data description',\n              extensions=c(\"Buttons\",'RowGroup'),\n              options=list(\n                  order=list(list(0, 'asc'), list(2,'asc')),  # Sort by the first column (index 0)\n                  rowGroup=list(dataSrc=0),    # Fixed rowGroup\n                  dom=\"Bfrtip\",\n                  columnDefs = list(list(visible=FALSE, targets= c(3,4))),\n                  buttons=c(\"copy\", \"csv\", \"pdf\"),\n                  initComplete = JS(\n                      \"function(settings, json) {\",\n                      \"$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});\",\n                      \"}\")\n              )\n) |&gt; \n    DT::formatStyle(\"time\",\n                    background=DT::styleColorBar(range(df$time), '#ee8b8b'),\n                    backgroundSize='98% 88%',\n                    backgroundRepeat='no-repeat',\n                    backgroundPosition='center')\n\n\n\n\n\n\n\n\n\n3.2.2 Closeness\n\n\nShow the code\nclosseness &lt;-sf::st_read(eisenberg_connection, \n                            layer = \"clossness_hospital_porto\")\nclosseness_no_geom &lt;- closseness |&gt;  \n                          arrange(ds_cnes, closeness) |&gt;\n                          mutate(lng= \n                              unlist(map(geom_hospital,1)),\n                           lat=\n                              unlist(map(geom_hospital,2)),\n                           closeness_norm = \n                          (closseness$closeness - min(closseness$closeness)) / (max(closseness$closeness) - min(closseness$closeness)) * 100,\n                          position = rank(-closeness),\n                          ds_cnes =stringr::str_to_title(ds_cnes)) |&gt;\n                  sf::st_drop_geometry()\n\nDT::datatable(subset(closseness_no_geom, select=c(\"position\",\"cd_cnes\",\"ds_cnes\",\"closeness\")),\n              extensions=\"Buttons\",\n                         options=list(\n                           dom=\"Bfrtip\",\n                           buttons=c(\"copy\",\"csv\",\"pdf\"),\n                            initComplete = JS(\n    \"function(settings, json) {\",\n    \"$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});\",\n    \"}\")\n                                  )\n              ) |&gt; \n    DT::formatStyle(\"closeness\",\n              background=DT::styleColorBar(range(closseness_no_geom$closeness),'#ee8b8b'),\n                backgroundSize = '98% 88%',\n  backgroundRepeat = 'no-repeat',\n  backgroundPosition = 'center') \n\n\n\n\n\n\n\n\n\nShow the code\n# Import he data\n## hospital with closenesss values\nclosseness &lt;-sf::st_read(eisenberg_connection, \n                            layer = \"clossness_hospital_porto\")\nclosseness_df &lt;- closseness |&gt;  arrange(ds_cnes, closeness) |&gt;\n                    mutate(lng= \n                              unlist(map(geom_hospital,1)),\n                           lat=\n                              unlist(map(geom_hospital,2)),\n                           closeness_norm = \n                          (closseness$closeness - min(closseness$closeness)) / (max(closseness$closeness) - min(closseness$closeness)) * 100,\n                          position = rank(-closeness))\n## Create Color palette for visualization\npal &lt;- colorQuantile(palette = \"OrRd\",closseness_df$closeness, n=4 )\n\n## Create leaflet product\n\nicons &lt;- makeAwesomeIcon(\n  icon = 'fa-heartbeat',\n  iconColor = \"#FFFFFF\",\n  markerColor = \"#57142c\",\n  library = \"fa\"\n)\nleaflet(closseness_df) |&gt;\n    addProviderTiles(providers$OpenStreetMap.HOT) |&gt;\n    addCircles(data =closseness_df , radius = ~sqrt(closeness)*10, fillOpacity = .50, color =~pal(closeness)) |&gt;\n  addAwesomeMarkers(data=closseness_df,\n                          icon =icons,\n                          popup= ~paste0(\"&lt;b&gt;Código CNES: &lt;/b&gt;\", cd_cnes, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt;Nome: &lt;/b&gt;\", ds_cnes, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt; Closeness&lt;/b&gt;:\", closeness, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt;Longitude: &lt;/b&gt;\", lng, \"&lt;br/&gt;\",\n                                   \"&lt;b&gt;Posição &lt;/b&gt;\", position, \"&lt;br/&gt;\"))"
  },
  {
    "objectID": "results.html#rq2-access",
    "href": "results.html#rq2-access",
    "title": "3  Results",
    "section": "3.3 RQ2: Access",
    "text": "3.3 RQ2: Access\n\nWhich healthcare facilities will be most affected by flooding based on accessibility metrics?"
  },
  {
    "objectID": "results.html#rq2-accessibility-analysis",
    "href": "results.html#rq2-accessibility-analysis",
    "title": "3  Results",
    "section": "3.3 RQ2: Accessibility analysis",
    "text": "3.3 RQ2: Accessibility analysis\n\nWhich healthcare facilities will be most affected by flooding based on accessibility metrics?"
  },
  {
    "objectID": "results.html#rq3-critical-infrastructures",
    "href": "results.html#rq3-critical-infrastructures",
    "title": "3  Results",
    "section": "3.4 RQ3: Critical infrastructures",
    "text": "3.4 RQ3: Critical infrastructures\n\nWhere are the most critical infrastructures located for accessing health facilities to reinforce urban resilience against flooding?"
  }
]