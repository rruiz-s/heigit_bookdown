# Results

Key variables:
- Centrality ---> vulnerability-resilience
- Accessibility ----> vulnerability-resilience

```{r}
#| echo: false
#| output: false
#| warning: false

# Load packages
lapply(c("tidyverse","DT","leaflet","sf","DBI", "RPostgres","dplyr", "mapview","leafpop","leaflet","leafsync","terra","raster","stars", "lwgeom","leaflet.extras2","RColorBrewer","tidygeocoder"),
       require,
       character.only =T)
# Connect to the server
eisenberg_connection <- DBI::dbConnect(RPostgres::Postgres(),
                          user= "docker",
                          password = "docker",
                          host = "localhost",
                          dbname="gis",
                          port = 25432)

## Import data
centrality_pre <- st_read(eisenberg_connection, "centrality_weighted_100_bidirect_cleaned")
centrality_post <- st_read(eisenberg_connection, "centrality_weighted_100_bidirect_cleaned_post")
flooding <- sf::st_read("~/heigit_bookdown/data/flooding_porto.geojson") 
```

## Data preparation
### OSM & ORS data

The code @lst-ghs-osmium covered the following area:

```{r}
#| eval: false
# Osmium command
osmium extract -b -51.2791,-30.1722,-50.9407,-29.8048 sul-240501.osm.pbf -o puerto_alegre_urban_center.osm.pbf
```

![](/media/bbox_porto_alegre_ghs.png){fig-align="center" width="50%"}
### Network
#### Post-event

```{sql}
#| connection: eisenberg_connection
#| eval: false
#| warning: false
#| message: false
#| echo: false

---- Generate the subset to be visualize

CREATE TABLE porto_alegre_net_largest_subset AS                  
SELECT
  st_intersection(net.the_geom, bbox.geom) 
FROM 
  porto_alegre_net_largest AS net
WHERE 
porto_alegre_net_largest.the_geom && subset_post_scenario_bbox; 
---- Generate the subset

CREATE TABLE subset_post_scenario_bbox AS
SELECT st_setsrid(
            st_makeenvelope(
              -51.214287,-30.020226,-51.12934,-29.945862),4326) AS geom;

--- pre_net_subset
CREATE TABLE porto_alegre_net_largest_subset AS                  
SELECT
  *
FROM 
  porto_alegre_net_largest AS net
WHERE 
net.the_geom && 
st_setsrid(
            st_makeenvelope(
              -51.214287,-30.020226,-51.12934,-29.945862),4326)
--- subset_network_in

------------- network inside

CREATE TEMPORARY TABLE flooding_subdivided_porto_join AS
SELECT st_union(the_geom) AS the_geom FROM flooding_subdivided_porto ;

----
CREATE TABLE porto_alegre_street_in_v3 AS
SELECT net.id,
    CASE 
        WHEN ST_Contains(flood.the_geom, net.the_geom)
        THEN net.the_geom
        ELSE st_intersection(net.the_geom, flood.the_geom)
    END AS  geom
FROM porto_alegre_net_largest_subset net
JOIN flooding_subdivided_porto_join flood
ON st_intersects(net.the_geom, flood.the_geom);         

--- subset_network_out
CREATE TABLE porto_alegre_street_out_v3 AS
SELECT net.*
FROM porto_alegre_net_largest_subset
WHERE net.id NOT IN (
    SELECT net.id
    FROM porto_alegre_street_in_v3 net);
    
---- network outside

CREATE TABLE porto_alegre_net_outside_v3 AS
WITH porto_alegre_ghs AS(
    SELECT 
       ghs.*
    FROM
       urban_center_4326 AS ghs
    JOIN
       nuts 
    ON 
       st_intersects(nuts.geom, ghs.geom)
    WHERE 
        nuts.shapename = 'Porto Alegre'),
--- Bounding Box that contained the GHS in Porto Alegre
porto_alegre_ghs_bbox AS(
    SELECT 
        st_setsrid(st_extent(geom),4326) as geom_bbox
    FROM 
        porto_alegre_ghs),
flooding_sul_subdivided AS (
        SELECT 
            st_subdivide(geom) as the_geom
        FROM
            flooding_rio_grande_do_sul),
exterior_ring_porto_alegre_v2 AS (
SELECT 
    ST_ExteriorRing((ST_Dump(union_geom)).geom) as geom
FROM (
    SELECT 
        ST_Union(flood.the_geom) as union_geom
    FROM 
        porto_alegre_ghs_bbox as bbox
    JOIN 
        flooding_sul_subdivided as flood
    ON 
        ST_Intersects(flood.the_geom, bbox.geom_bbox)
) AS subquery)
SELECT net.id,
    CASE
        WHEN NOT ST_Contains(flood.geom, net.the_geom)
        THEN net.the_geom
            ELSE st_intersection(net.the_geom, flood.geom)
    END AS  geom,
    net.target,
       net.source,
       cost,
       "unidirectid",
       "bidirectid"
FROM
porto_alegre_net_largest_subset AS net
JOIN exterior_ring_porto_alegre_v2 flood ON
st_intersects(net.the_geom, flood.geom)
WHERE 
  net.the_geom && 
    st_setsrid(
    st_makeenvelope(-51.214287,-30.020226,-51.12934,-29.945862),4326);
----
--- For the network
CREATE INDEX idx_porto_alegre_net_outside_v2 ON porto_alegre_net_outside_v2 USING gist (geom);

CLUSTER porto_alegre_net_outside_v2 USING idx_porto_alegre_net_outside_v2;

--- For the flooding mask
CREATE INDEX flooding_sul_subdivided_idx ON flooding_sul_subdivided USING gist (the_geom);

CLUSTER flooding_sul_subdivided USING flooding_sul_subdivided_idx;

---- Before doing difference
VACUUM(FULL, ANALYZE) porto_alegre_net_outside_v2;
VACUUM(FULL, ANALYZE) flooding_sul_subdivided;
----
CREATE INDEX idx_porto_alegre_net_outside_v3 ON porto_alegre_net_outside_v3 USING gist (geom);

CLUSTER porto_alegre_net_outside_v3 USING idx_porto_alegre_net_outside_v3;

--- For the flooding mask
CREATE INDEX flooding_subdivided_porto_join_idx ON flooding_subdivided_porto_join USING gist (the_geom);

CLUSTER flooding_subdivided_porto_join USING flooding_subdivided_porto_join_idx ;

---- Before doing difference
VACUUM(FULL, ANALYZE) porto_alegre_net_outside_v3;
VACUUM(FULL, ANALYZE) flooding_subdivided_porto_join;

----

CREATE TABLE flooding_symple as 
SELECT st_union(geom) as the_geom FROM flooding_cleaned_porto_union_simple;

CREATE INDEX flooding_symple_idx ON flooding_symple USING gist (the_geom);
CLUSTER flooding_symple USING flooding_symple_idx;

CREATE TABLE difference_outside_flood_v4 AS
SELECT net.id,
        target,
        source,
        cost,
        unidirectid,
        bidirectid,
st_difference(net.geom, flood.the_geom) AS the_geom
FROM porto_alegre_net_outside_v3 AS net,
flooding_symple  AS flood;

-----------
CREATE TABLE porto_alegre_street_united_v3 AS
SELECT *
FROM porto_alegre_street_out_v3
UNION
SELECT *
FROM difference_outside_flood_v4;

--- Final product: porto_alegre_street_united_v2
```


## RQ1: Centrality analysis

>How does road connectivity change after being impacted by flooding based on
connectivity metrics?

### Sum Edge Betweenness

```{r}
#| eval: false

### natural breaks
#### For pre-event: 1644, 468, 142
centrality_pre$centrality_fct <- cut(centrality_pre$centrality,
                  breaks=c(0,142,468,1644),
                  labels =c("low","medium","high"),
                  include.lowest= TRUE,
                  right =FALSE)
#### natural breaks:  81, 230, 582
centrality_post$centrality_fct <- cut(centrality_post$centrality,
                  breaks=c(0,81,230,582),
                  labels =c("low","medium","high"),
                  include.lowest= TRUE,
                  right =FALSE)
### 
centrality_pre_map <- mapview::mapview(centrality_pre,
                                       zcol="centrality_fct",
                                        lwd ="centrality",
                                       layer.name ="Centrality Pre-Event",
              popup=popupTable(centrality_pre, 
                               zcol=c("id","centrality","bidirectid"))) 
centrality_post_map <- mapview::mapview(centrality_post,
                                       zcol="centrality_fct",
                                        lwd = "centrality",
                                       layer.name ="Centrality Post-Event",
              popup=popupTable(centrality_pre, 
                               zcol=c("id","centrality","bidirectid"))) 

centrality_pre_map | centrality_post_map + mapview(flooding,
          color="darkblue",
          alpha.regions= 0.5,
          layer.name="Flooding layer")

```

```{=html}

<iframe width="760" height="500" src="/media/centrality_map_results.html" title = "Sum Edge Betweenness in the Urban Settlement located in Porto Alegre "></iframe>

```

Meter tabla que incluye georefernciar

```{r}
#| message: false
#| warning: false
#| eval: false


library(plyr)
## Categories for pre-flooding or post-flooding
df_centrality_pre <- centrality_pre |>
                      sf::st_drop_geometry() |>
                      mutate(event = "pre-flooding") 
df_centrality_post <- centrality_post |>
                        sf::st_drop_geometry() |>
                    mutate(event = "post-flooding")

#### For pre-event: 1644, 468, 142
df_centrality_pre$centrality_fct <- cut(df_centrality_pre$centrality,
                  breaks=c(0,142,468,1644),
                  labels =c("low","medium","high"),
                  include.lowest= TRUE,
                  right =FALSE)
#### natural perk:  81, 230, 582
df_centrality_post$centrality_fct <- cut(df_centrality_post$centrality,
                  breaks=c(0,81,230,582),
                  labels =c("low","medium","high"),
                  include.lowest= TRUE,
                  right =FALSE)
## Join both in one dataframe
df_centrality_both <- left_join(df_centrality_pre,
                    df_centrality_post,
                    by = 'id',
                    suffix=c("_pre","_post")) |>    dplyr::select(c("id","bidirectid_pre","bidirectid_post","centrality_pre","centrality_post","centrality_fct_pre","centrality_fct_post","event_post","event_pre")) |>
  mutate(centrality_post = replace_na(centrality_post, 0)) ## Roads covered by the flooding appeared as NA in the post-scenario, replace tha NA value for 0

## Calculate change on centrality after being impacted by flooding 
df_centrality_both <-  df_centrality_both |>
            mutate(centrality_diff = centrality_post-centrality_pre)
### Obtain distribution using quantiles
df_centrality_both_quantiles <- quantile(df_centrality_both$centrality_diff, na.rm =TRUE)
### Filter the worst scenario, most negative values below second quartile
df_centrality_negative_outlier <- df_centrality_both |>
                        filter( centrality_diff <= df_centrality_both_quantiles[2])
### Join with original data to obtain again geometry
df_centrality_negative_outlier_geom <- df_centrality_negative_outlier |>
                        arrange(centrality_diff) |>
                        slice(1:1000) |>
                        left_join(centrality_pre, by = "id") |>
                    mutate(the_geom_centroid = st_centroid(the_geom),
                           lon = st_coordinates(the_geom_centroid)[,1],
                           lat = st_coordinates(the_geom_centroid)[,2])
# Obtain a subset of the 500 observations oredered by lowest values on centrality difference
df_centrality_negative_outlier_geom_unique <- df_centrality_negative_outlier_geom |> 
  distinct(centrality_pre, .keep_all = TRUE) 
# Reverse geocoding to obtain the address based on the centroids
df_centrality_negative_outlier_distinct_address <-  tidygeocoder::reverse_geocode(df_centrality_negative_outlier_geom_unique, lat=lat, lon=lon, method="osm")
## Create ID for the found addresses (97)
df_centrality_negative_outlier_distinct_address$address_number <- seq(1, 167,1)

df_centrality_negative_outlier_distinct_address$short_address <- str_extract(df_centrality_negative_outlier_distinct_address$address, "^[^,]+, [^,]+") 
df_centrality_negative_outlier_distinct_address$centrality_diff_perc <- round(((df_centrality_negative_outlier_distinct_address$centrality_post - df_centrality_negative_outlier_distinct_address$centrality_pre) / df_centrality_negative_outlier_distinct_address$centrality_pre *100),2)
  
## DT Table
DT::datatable(subset(df_centrality_negative_outlier_distinct_address, select=c("address_number", "short_address","centrality_pre", "centrality_post","centrality_diff","centrality_diff_perc","id","source","target","the_geom")), 
              colnames= c("ID","Address","Pre-Centrality", "Post-Centrality","Diff-Centrality","Diff-Centrality(%)","id_1","source","target","the_geom"),
              filter="top",
              class='compact', rownames=FALSE, escape=FALSE, caption='Data description',
              extensions=c("Buttons",'RowGroup'),
              options=list(
                  order=list(list(5, 'desc'), list(2,'desc')),  # Sort by the first column (index 5)
                  dom="Bfrtip",
                  columnDefs = list(list(visible=FALSE, targets= c(6,7,8,9))),
                  buttons=c("copy", "csv", "pdf"),
                  initComplete = JS(
                      "function(settings, json) {",
                      "$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});",
                      "}")
              )
) |> 
      DT::formatStyle("centrality_pre",
     background=DT::styleColorBar(range(df_centrality_negative_outlier_distinct_address$centrality_pre), '#ee8b8b'),
                    backgroundSize='98% 88%',
                    backgroundRepeat='no-repeat',
                    backgroundPosition='center') 
```


```{=html}

<iframe width="760" height="500" src="/media/centrality_table_results.html" title = "Sum Edge Betweenness in the Urban Settlement located in Porto Alegre "></iframe>

```
Meter gráfica

```{r}
#| warming: false
#| message: false

library(plyr)
# Tidy data and wrangling
centrality_post$event <- "post-flooding"
centrality_pre$event <- "pre-flooding"  
centrality_both <- rbind(centrality_post[,c("id","centrality","event")] ,
                                   centrality_pre[,c("id","centrality","event")])
mu <- plyr::ddply(centrality_both, "event", summarise, grp.mean=mean(centrality))

# Create histogram
ggplot(centrality_both, aes(x=centrality, fill=event)) +
                    geom_histogram(alpha=0.4,) + scale_x_log10() +
                  labs(title = "Centrality analysis",
                      subtitle= "Histogram on log10 scale",
                      x = " Betweenness centrality (centrality)",
                      y = "Frequency (count)") +
  theme(plot.title=element_text(family ="bold", hjust=0.5),
        plot.subtitle = element_text(colour="#626262", hjust=0.5),
        legend.position='bottom')
```


```{r}
## Import
#| warming: false
#| message: false

df_centrality_pre <- centrality_pre |>
                        sf::st_drop_geometry() |>
                        mutate(event = "pre-flooding") 
df_centrality_post <- centrality_post |> 
                          sf::st_drop_geometry() |>
                              mutate(event = "post-flooding")
##
df_centrality_both_barplot <- dplyr::bind_rows(df_centrality_pre,
                                               df_centrality_post)
### percentiles
q <- quantile(df_centrality_both_barplot$centrality)
q_pre <- quantile(
  df_centrality_pre[df_centrality_pre$event == 'pre-flooding',]$centrality)
q_post <- quantile(
  df_centrality_post[df_centrality_post$event == 'post-flooding',]$centrality)
### Centrality
df_centrality_both_barplot_cat <- na.omit(df_centrality_both_barplot) |> 
  mutate(centrality_cat=as.factor(case_when(
    centrality <= q_pre[2] ~ "Q1",
    centrality <= q_pre[3] ~ "Q2",
    centrality <= q_pre[4] ~ "Q3",
    centrality >= q_pre[4] ~ "Q4",
    TRUE ~ "missing")))  
## tidy data
barplot_event_cat_sum <- df_centrality_both_barplot_cat |> 
                          dplyr::group_by(event, centrality_cat) |>
                           dplyr::summarise(sum_centrality = sum(centrality))
#basic plot
 barplot_event_cat_sum |>  
  ggplot(aes(x=centrality_cat,
              y=sum_centrality,
              fill=event)) +
  geom_col(width=0.5, position="dodge") +
  labs(title = "Centrality analysis",
       subtitle= "Barplot grouped by the post and pre event",
       x = " Quantiles",
       y = "Sum of edge betweenness") +
  theme(plot.title=element_text(family ="bold", hjust=0.5),
        plot.subtitle = element_text(colour="#626262", hjust=0.5),
        legend.position='bottom')

```


```{r}
#| warning: false
#| message: false
#| eval: false
#| echo: false

df_centrality_both_pareto_cat <- na.omit(
  df_centrality_both_barplot) |> 
  mutate(centrality_cat=as.factor(
      case_when(
    centrality <= quantile(
        df_centrality_pre[df_centrality_pre$event == 'pre-flooding',]$centrality, .20) ~ "20%",
    centrality <= quantile(
        df_centrality_pre[df_centrality_pre$event == 'pre-flooding',]$centrality, .40) ~ "40%",
    centrality <= quantile(
        df_centrality_pre[df_centrality_pre$event == 'pre-flooding',]$centrality, .60) ~ "60%",
    centrality <= quantile(
        df_centrality_pre[df_centrality_pre$event == 'pre-flooding',]$centrality, .80) ~ "80%",
    centrality >= quantile(
        df_centrality_pre[df_centrality_pre$event == 'pre-flooding',]$centrality, .80) ~ "99%",
    TRUE ~ "missing")))  

d <- df_centrality_both_pareto_cat |>
            st_drop_geometry() |>
            filter(event=="pre-flooding") |>
            dplyr::group_by(centrality_cat) |> dplyr::summarise(centrality_sum=sum(centrality)) |> 
  arrange(desc(centrality_sum)) |>
  mutate(cumsum=cumsum(centrality_sum),
         freq=round(centrality_sum/sum(centrality_sum),3),
         cum_freq=cumsum(freq))
## Saving Parameters 

def_par <- par() 

# New margins
par(mar=c(5,5,4,5)) 

## plot bars, pc will hold x values for bars
pc = barplot(d$centrality_sum,
             width = 1, space = 0.2, border = NA, axes = F,
             ylim = c(0, 1.05 * max(d$centrality_sum, na.rm = T)), 
             ylab = "Counts" , cex.names = 0.7, 
             names.arg = d$centrality_cat,
             main = "Pareto Chart")

## anotate left axis
axis(side = 2, at = c(0, d$centrality_sum), las = 1, col.axis = "grey62", col = "grey62", tick = T, cex.axis = 0.8)

## frame plot
box( col = "grey62")

## Cumulative Frequency Lines 
px <- d$cum_freq * max(d$centrality_sum, na.rm = T)
lines(pc, px, type = "b", cex = 0.7, pch = 19, col="#d50038")

## Annotate Right Axis
axis(side = 4, at = c(0, px), labels = paste(c(0, round(d$cum_freq * 100)) ,"%",sep=""), 
     las = 1, col.axis = "grey62", col = "#d50038", cex.axis = 0.8, col.axis = "#d50038")

## restoring default paramenter
par(def_par) 
```


### Closeness


```{r}

# Import he data
## hospital with closenesss values
closseness <-sf::st_read(eisenberg_connection, 
                            layer = "clossness_hospital_porto")
closseness_df <- closseness |>  arrange(ds_cnes, closeness) |>
                    mutate(lng= 
                              unlist(map(geom_hospital,1)),
                           lat=
                              unlist(map(geom_hospital,2)),
                           closeness_norm = 
                          (closseness$closeness - min(closseness$closeness)) / (max(closseness$closeness) - min(closseness$closeness)) * 100,
                          position = rank(-closeness))
## Create Color palette for visualization
pal <- colorQuantile(palette = "OrRd",closseness_df$closeness, n=4 )

## Create leaflet product

icons <- makeAwesomeIcon(
  icon = 'fa-heartbeat',
  iconColor = "#FFFFFF",
  markerColor = "#57142c",
  library = "fa"
)
leaflet(closseness_df) |>
    addProviderTiles(providers$OpenStreetMap.HOT) |>
    addCircles(data =closseness_df , radius = ~sqrt(closeness)*10, fillOpacity = .50, color =~pal(closeness)) |>
  addAwesomeMarkers(data=closseness_df,
                          icon =icons,
                          popup= ~paste0("<b>Código CNES: </b>", cd_cnes, "<br/>",
                                   "<b>Nome: </b>", ds_cnes, "<br/>",
                                   "<b> Closeness</b>:", closeness, "<br/>",
                                   "<b>Longitude: </b>", lng, "<br/>",
                                   "<b>Posição </b>", position, "<br/>"))

```

```{r}
closseness <-sf::st_read(eisenberg_connection, 
                            layer = "clossness_hospital_porto")
closseness_no_geom <- closseness |>  
                          arrange(ds_cnes, closeness) |>
                          mutate(lng= 
                              unlist(map(geom_hospital,1)),
                           lat=
                              unlist(map(geom_hospital,2)),
                           closeness_norm = 
                          (closseness$closeness - min(closseness$closeness)) / (max(closseness$closeness) - min(closseness$closeness)) * 100,
                          position = rank(-closeness),
                          ds_cnes =stringr::str_to_title(ds_cnes)) |>
                  sf::st_drop_geometry()

DT::datatable(subset(closseness_no_geom, select=c("position","cd_cnes","ds_cnes","closeness")),
              extensions="Buttons",
                         options=list(
                           dom="Bfrtip",
                           buttons=c("copy","csv","pdf"),
                            initComplete = JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});",
    "}")
                                  )
              ) |> 
    DT::formatStyle("closeness",
              background=DT::styleColorBar(range(closseness_no_geom$closeness),'#ee8b8b'),
                backgroundSize = '98% 88%',
  backgroundRepeat = 'no-repeat',
  backgroundPosition = 'center') 
```

## RQ2:  Accessibility analysis

> Which healthcare facilities will be most affected by flooding based on accessibility
metrics?

### Sum Edge Betweenness:

```{sql}
#| eval: false

---- Based on a max of 100*100 / 22 = 454   
SELECT count(*) FROM hospital_rs_node_v2;  --- 22 POI: Hospitals 
----- Create origin   
CREATE TABLE weight_sampling_454_origin  AS
WITH porto_454_origin AS (
        SELECT
            * 
        FROM 
            od_2728_snapped 
        ORDER BY random() 
        LIMIT 454)
SELECT * FROM  porto_454_origin;

--- Create destinations in this case hospitals
CREATE TABLE hospital_rs_destination AS
SELECT 
	cd_cnes,
	ds_cnes,
	id,
	geom_node
FROM 
	hospital_rs_node_v2;  --- 22 POI: Hospitals    
	
---- Create hospitald destinations from closeness 
CREATE TABLE hospital_rs_destination AS
WITH clossness_hospital_porto_id AS (
SELECT 
	n.*,
	v.id
FROM 
	clossness_hospital_porto AS n
JOIN
	porto_alegre_net_largest_vertices_pgr AS v
	ON  st_intersects(n.geom_node, v.the_geom))
SELECT 
	cd_cnes,
	ds_cnes,
	id,
	closeness,
	geom_node
FROM 
	clossness_hospital_porto_id; 	
---- Create index for origin
CREATE INDEX weight_sampling_454_origin_net_id ON weight_sampling_454_origin USING hash(net_id);
CREATE INDEX weight_sampling_454_origin_geom ON weight_sampling_454_origin USING gist(the_geom);
---- Create index for destination
CREATE INDEX hospital_rs_destination_net_id ON hospital_rs_destination USING btree(id);
CREATE INDEX hospital_rs_destination_geom ON hospital_rs_destination USING gist(geom_node);
---- Cluster
CLUSTER porto_alegre_net_largest USING idx_porto_alegre_net_largest_geom;
---- Vacuum clean
VACUUM(full, ANALYZE) weight_sampling_454_origin;
VACUUM(full, ANALYZE) hospital_rs_destination;
VACUUM(full, ANALYZE) porto_alegre_net_largest;
---- Running the query
EXPLAIN ANALYZE
 CREATE TABLE centrality_424_hospitals_porto_end_id_centrality AS
 SELECT   
 b.vid,
 j.end_id,
 b.the_geom,
 count(the_geom) as centrality 
 FROM  pgr_dijkstra('SELECT  id,
							 source,
							target,
							cost
				      FROM porto_alegre_net_largest',
				      ARRAY(SELECT net_id AS origin_id FROM weight_sampling_454_origin),
				      ARRAY(SELECT id AS destination_id FROM hospital_rs_destination),
				      directed := TRUE) j
				      left JOIN porto_alegre_net_largest AS b
				      ON j.edge = b.id
				      GROUP BY  b.id, j.end_vid, b.the_geom
				      ORDER BY centrality DESC;  
 ---- Group by end_vid that represent destination
select * from hospital_rs_destination ;
				     
SELECT * FROM centrality_424_hospitals_porto_end_id_centrality; 				     
SELECT 
	centrality.end_vid,
	hospitals.cd_cnes,
	hospitals.ds_cnes,
	count(centrality.the_geom)::int AS sum_centrality,
	max(st_length(centrality.the_geom::geography))::int AS length
FROM 
	centrality_424_hospitals_porto_end_id_centrality AS centrality
LEFT JOIN 
	hospital_rs_destination AS hospitals ON  centrality.end_vid = hospitals.id 
GROUP BY end_vid, cd_cnes, ds_cnes;

```

```{sql}
#| eval: false

### Post-scenario

SELECT count(*) FROM hospital_rs_node_v2;  --- 22 POI: Hospitals 
----- Create origin   
CREATE TABLE weight_sampling_454_origin_post  AS
WITH porto_454_origin_post AS (
        SELECT
            * 
        FROM 
            od_2728_snapped_post 
        ORDER BY random() 
        LIMIT 454)
SELECT * FROM  porto_454_origin_post;

--- Create destinations in this case hospitals
CREATE TABLE hospital_rs_destination AS
SELECT 
    cd_cnes,
    ds_cnes,
    id,
    geom_node
FROM 
    hospital_rs_node_v2;  --- 22 POI: Hospitals    
    
---- Create hospitald destinations from closeness 
CREATE TABLE hospital_rs_destination AS
WITH clossness_hospital_porto_id AS (
SELECT 
    n.*,
    v.id
FROM 
    clossness_hospital_porto AS n
JOIN
    porto_alegre_net_largest_vertices_pgr AS v
    ON  st_intersects(n.geom_node, v.the_geom))
SELECT 
    cd_cnes,
    ds_cnes,
    id,
    closeness,
    geom_node
FROM 
    clossness_hospital_porto_id;    
---- Create index for origin

CREATE INDEX weight_sampling_454_origin_net_id ON weight_sampling_454_origin_post USING hash(net_id); 
CREATE INDEX weight_sampling_454_origin_geom ON weight_sampling_454_origin_post USING gist(the_geom);
---- Create index for destination
CREATE INDEX hospital_rs_destination_net_id ON hospital_rs_destination USING btree(id);
CREATE INDEX hospital_rs_destination_geom ON hospital_rs_destination USING gist(geom_node);
---- Cluster
CLUSTER porto_alegre_net_largest USING idx_porto_alegre_net_largest_geom;
---- Vacuum clean
VACUUM(full, ANALYZE) weight_sampling_454_origin_post;
VACUUM(full, ANALYZE) hospital_rs_destination;
VACUUM(full, ANALYZE) prueba_largest_network_post;
---- Running the query
EXPLAIN ANALYZE
 CREATE TABLE centrality_424_hospitals_porto_end_id_centrality_post AS
 SELECT   
 b.ogc_fid,
 j.end_vid,
 b.the_geom,
 count(the_geom) as centrality 
 FROM  pgr_dijkstra('SELECT  ogc_fid AS id,
                             fromid AS source,
                            toid AS target,
                            weight AS cost
                      FROM prueba_largest_network_post',
                      ARRAY(SELECT net_id AS origin_id FROM weight_sampling_454_origin_post),
                      ARRAY(SELECT id AS destination_id FROM hospital_rs_destination),
                      directed := TRUE) j
                      left JOIN prueba_largest_network_post AS b
                      ON j.edge = b.ogc_fid
                      GROUP BY  b.ogc_fid, j.end_vid, b.the_geom
                      ORDER BY centrality DESC;  
 ---- Group by end_vid that represent destination
CREATE TABLE centrality_424_hospitals_porto_end_id_centrality_post_group AS
SELECT 
    centrality.end_vid,
    hospitals.cd_cnes,
    hospitals.ds_cnes,
    max(centrality.centrality)::int AS max_centrality,
    max(st_length(centrality.the_geom::geography))::int AS length
FROM 
    centrality_424_hospitals_porto_end_id_centrality_post AS centrality
LEFT JOIN 
    hospital_rs_destination AS hospitals ON  centrality.end_vid = hospitals.id 
GROUP BY end_vid, cd_cnes, ds_cnes;

```


```{r}
#| eval: false

## Eisenberg
hospitals_betweenness_pre <- st_read(eisenberg_connection, "centrality_424_hospitals_porto_end_id_centrality") 
hospitals_betweenness_post <- st_read(eisenberg_connection,"centrality_424_hospitals_porto_end_id_centrality_post")
### Locally
hospitals_betweenness_pre_local <- st_read(eisenberg_connection, Id(schema="heigit", table = "centrality_424_hospitals_porto_end_id_centrality_group"))
hospitals_betweenness_post_local <- st_read(eisenberg_connection, Id(schema="heigit", table = "centrality_424_hospitals_porto_end_id_centrality_post_group"))
hospitals_betweenness_pre_local$event <- "pre-event"
hospitals_betweenness_post_local$event <- "post-event"
## Import
hospitals_betweenness_both_long <- hospitals_betweenness_pre_local |> bind_rows(hospitals_betweenness_post_local) |> subset(select=c("cd_cnes","ds_cnes","max_centrality","event")) |> pivot_wider(
    names_from = event,
    values_from = max_centrality,
  ) |>  rename( betwenness_pre= `pre-event`,
                betwenness_post= `post-event`) 
hospitals_betweenness_both_long[is.na(hospitals_betweenness_both_long)] <- 0    
## pivot
hospitals_betweenness_long <- hospitals_betweenness_both_long |>
                                  mutate(diff_betweenness_percent =
                                           (betwenness_post-betwenness_pre)/(betwenness_pre)*100,
                                         diff = betwenness_post-betwenness_pre,
                                         letter = LETTERS[1:22])  |>
  arrange(letter) |> 
                             pivot_longer(
                                     c(betwenness_pre,betwenness_post),
                                      names_to="betweenness_type",
                                      values_to="betweenness_value") 
                   
hospitals_betweenness_long_pre <- 
  hospitals_betweenness_long |>
            filter(betweenness_type == "betwenness_pre")
hospitals_betweenness_long_post <- 
  hospitals_betweenness_long |>
  filter(betweenness_type == "betwenness_post")
##

df_labels_betweenness <- hospitals_betweenness_long |> 
  group_by(letter) |> 
  summarize(midpoint = mean(betweenness_value), 
            diff_betweenness_percent = first(diff_betweenness_percent))
##
p <- ggplot(hospitals_betweenness_long, aes(x=betweenness_value, y=reorder(letter, desc(diff_betweenness_percent)))) +
  geom_segment(data=hospitals_betweenness_long_pre,
               aes(x=betweenness_value, y = letter,
                   yend=hospitals_betweenness_long_post$letter, xend=hospitals_betweenness_long_post$betweenness_value)) +
  geom_point(aes(x=betweenness_value, y = letter, color = betweenness_type, size=2.5))  +
  geom_text(data = df_labels_betweenness, aes(x = midpoint, y = letter, label = paste0(round(diff_betweenness_percent,2), " %")), 
            vjust = 1.5, size = 3.5, color = "red") +
    geom_text(aes(label = betweenness_value, color = betweenness_type), vjust = -1, size=3.5) +  # Label the points with centrality_value
   scale_color_brewer(palette = "Set1", direction = 1) +
  scale_y_discrete(expand=c(0.05,0.05)) +
  theme_minimal() +
  labs(title = "Centrality analysis",
       subtitle= "Change of centrality based on sum edge betweenness in hospitals",
       y = " Hospitals",
       x = "Sum Edge Betweenness") +
  theme(plot.title=element_text(family ="bold", hjust=0.5),
        axis.text.y = element_text(size = 16),
        plot.subtitle = element_text(colour="#626262", hjust=0.5),
        legend.position='bottom') 

### table

df_hospitals_betweenness_both_compare <- hospitals_betweenness_both_long |> 
                                              mutate(diff_betweenness_percent = 
                                                          round((betwenness_post-betwenness_pre)/(betwenness_pre)*100,2),
                                                      diff = betwenness_post-betwenness_pre,
                                                      letter = LETTERS[1:22],
                                                      ds_cnes = stringr::str_to_title(ds_cnes))
                                                  
  
DT::datatable(subset(df_hospitals_betweenness_both_compare,
                     select=c("letter","cd_cnes","ds_cnes","betwenness_pre","betwenness_post","diff_betweenness_percent")),
              colnames=c("ID","Code","Name","Betweenness Pre","Betweenness Post","Diff(%)"),
              filter="top",
              extensions="Buttons",
                         options=list(
                           dom="Bfrtip",
                           buttons=c("copy","csv","pdf"),
                            initComplete = JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});",
    "}")
                                  )
              ) |> 
    DT::formatStyle("betwenness_pre",
              background=DT::styleColorBar(range(df_hospitals_betweenness_both_compare$betwenness_pre),'#ee8b8b'),
                backgroundSize = '98% 88%',
  backgroundRepeat = 'no-repeat',
  backgroundPosition = 'center') |>
    DT::formatStyle("betwenness_post",
              background=DT::styleColorBar(range(df_hospitals_betweenness_both_compare$betwenness_pre),'#8ba1b3'),
                backgroundSize = '98% 88%',
  backgroundRepeat = 'no-repeat',
  backgroundPosition = 'center')

```

### Closeness:





```{r}
#| eval: false
#| echo: false

## Import
hospitals_closeness_both <- st_read(eisenberg_connection, "hospitals_closeness_both") 
## pivot
hospitals_closeness_long <- hospitals_closeness_both |>
                                  mutate(diff_closeness_percent =
                                           (closeness_post-closeness_pre)/(closeness_pre)*100,
                                         diff = closeness_post-closeness_pre,
                                         letter = LETTERS[1:20]) |>
  arrange(letter) |> 
                             pivot_longer(
                                     c(closeness_pre,closeness_post),
                                      names_to="closeness_type",
                                      values_to="closeness_value") 
                   
hospitals_closeness_long_pre <- 
  hospitals_closeness_long |>
            filter(closeness_type == "closeness_pre")
hospitals_closeness_long_post <- 
  hospitals_closeness_long |>
  filter(closeness_type == "closeness_post")
##

df_labels <- hospitals_closeness_long |> 
  group_by(letter) |> 
  summarize(midpoint = mean(closeness_value), 
            diff_closeness_percent = first(diff_closeness_percent))
##
p <- ggplot(hospitals_closeness_long, aes(x=closeness_value, y=reorder(letter, desc(diff_closeness_percent)))) +
  geom_segment(data=hospitals_closeness_long_pre,
               aes(x=closeness_value, y = letter,
                   yend=hospitals_closeness_long_post$letter, xend=hospitals_closeness_long_post$closeness_value)) +
  geom_point(aes(x=closeness_value, y = letter, color = closeness_type, size=2.5))  +
  geom_text(data = df_labels, aes(x = midpoint, y = letter, label = paste0(round(diff_closeness_percent,2), " %")), 
            vjust = 1.5, size = 3.5, color = "red") +
    geom_text(aes(label = closeness_value, color = closeness_type), vjust = -1, size=3.5) +  # Label the points with centrality_value
   scale_color_brewer(palette = "Set1", direction = 1) +
  scale_y_discrete(expand=c(0.05,0.05)) +
  theme_minimal() +
  labs(title = "Centrality analysis",
       subtitle= "Change of centrality of hospitals due to the flooding",
       y = " Hospitals",
       x = "Closenness") +
  theme(plot.title=element_text(family ="bold", hjust=0.5),
        axis.text.y = element_text(size = 16),
        plot.subtitle = element_text(colour="#626262", hjust=0.5),
        legend.position='bottom') +
  xlim(0,47000) 

```

![](/media/accessibility_test2.png)



```{r}
hospitals_closeness_both <- st_read(eisenberg_connection, "hospitals_closeness_both") 
df_hospitals_closeness_both_compare <- hospitals_closeness_both |> 
                                              mutate(diff_closeness_percent = 
                                                          round((closeness_post-closeness_pre)/(closeness_pre)*100,2),
                                                      diff = closeness_post-closeness_pre,
                                                      letter = LETTERS[1:20],
                                                      ds_cnes = stringr::str_to_title(ds_cnes)) |> 
                                                  sf::st_drop_geometry() 
                                                  
  
DT::datatable(subset(df_hospitals_closeness_both_compare,
                     select=c("letter","cd_cnes","ds_cnes","closeness_pre","closeness_post","diff_closeness_percent")),
              colnames=c("ID","Code","Name","Closeness Pre","Closeness Post","Diff(%)"),
              filter="top",
              extensions="Buttons",
                         options=list(
                           dom="Bfrtip",
                           buttons=c("copy","csv","pdf"),
                            initComplete = JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#d50038', 'color': '#fff'});",
    "}")
                                  )
              ) |> 
    DT::formatStyle("closeness_pre",
              background=DT::styleColorBar(range(df_hospitals_closeness_both_compare$closeness_pre),'#ee8b8b'),
                backgroundSize = '98% 88%',
  backgroundRepeat = 'no-repeat',
  backgroundPosition = 'center') |>
    DT::formatStyle("closeness_post",
              background=DT::styleColorBar(range(df_hospitals_closeness_both_compare$closeness_pre),'#8ba1b3'),
                backgroundSize = '98% 88%',
  backgroundRepeat = 'no-repeat',
  backgroundPosition = 'center')
```


## RQ3: Critical infrastructures

> Where are the most critical infrastructures located for accessing health facilities
to reinforce urban resilience against flooding?